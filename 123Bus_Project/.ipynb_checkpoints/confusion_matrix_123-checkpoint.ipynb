{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51442d5b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00991962",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch_geometric\n",
    "!pip install captum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fa217f",
   "metadata": {},
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e871f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jupytext --to ipynb Comparative_Cheb_GCN.py\n",
    "# Don't forget to upload model as well\n",
    "!unzip numpy_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c8b472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce35614",
   "metadata": {},
   "source": [
    "\n",
    "!pip install torch_geometric\n",
    "!pip install pdf2image\n",
    "!apt-get install poppler-utils\n",
    "# !pip install captum\n",
    "\n",
    "from google.colab import files\n",
    "files.upload()\n",
    "\n",
    "jupytext --to ipynb Comparative_Cheb_GCN.py\n",
    "Don't forget to upload model.pth as well\n",
    "!unzip numpy_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a535d2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.datasets import TUDataset, Planetoid\n",
    "from torch_geometric.nn import GCNConv, Set2Set\n",
    "from torch_geometric.explain import GNNExplainer\n",
    "import torch_geometric.transforms as T\n",
    "import torch\n",
    "#import torch.nn.functional as F\n",
    "import os\n",
    "from tqdm import tqdm, trange\n",
    "#\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a039ab4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading saved model architecture\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import ChebConv\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.nn import TransformerConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.nn.pool import global_max_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daa83db",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        # self.conv1 = GCNConv(6, 512, improved = True)\n",
    "        # self.conv2 = GCNConv(512, 256, improved = True)\n",
    "\n",
    "        # self.conv1 = ChebConv(6, 512, K = 2)\n",
    "        # self.conv2 = ChebConv(512,256, K = 2)\n",
    "\n",
    "        self.conv1 = ChebConv(6, 256, K = 3)\n",
    "        self.conv2 = ChebConv(256,256, K = 4)\n",
    "        self.conv3 = ChebConv(256, 256, K = 5)\n",
    "        # self.fc1 = Linear(256, 512)\n",
    "        # self.fc2 = Linear(512, 256)\n",
    "\n",
    "        # self.conv1 = GATConv(6, 256, heads = 4)\n",
    "        # self.conv2 = GATConv(256*4,64, heads = 1, concat=False)\n",
    "\n",
    "        # self.conv1 = TransformerConv(6, 200, heads = 3)\n",
    "        # self.conv2 = TransformerConv(200*3,256, heads = 1, concat=False)\n",
    "\n",
    "        self.lin = Linear(256, 120)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = x.relu()\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "        # = global_max_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # x = self.fc1(x)\n",
    "        # x = x.relu()\n",
    "        # x = self.fc2(x)\n",
    "        # x = x.relu()\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.2, training=self.training) #0.5\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd43fa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(hidden_channels=464)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29ec86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(os.getcwd()+ \"/model.pth\")\n",
    "# model_save_location = os.getcwd()+ \"/model.pth\"\n",
    "print(os.getcwd()+ \"/model_123.pt\")\n",
    "model_save_location = os.getcwd()+ \"/model_123.pt\"\n",
    "model.load_state_dict(torch.load(model_save_location, map_location=torch.device('cpu')))\n",
    "print(model.conv3)\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18aa7741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import networkx as nx\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae54f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# +\n",
    "import time\n",
    "#Extract Training Data\n",
    "#Loads IEEE34 Bus Simulation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19887ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b650315",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_data = np.load(path+\"/new_data.npy\",allow_pickle = True)\n",
    "numpy_data = np.squeeze(numpy_data)\n",
    "print(numpy_data)\n",
    "print(numpy_data.shape)\n",
    "print(numpy_data.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a36680f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "value_data = np.load(path+\"/new_labels.npy\",allow_pickle = True)\n",
    "print(value_data)\n",
    "print(value_data.shape)\n",
    "print(value_data.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084d1485",
   "metadata": {},
   "outputs": [],
   "source": [
    "NodeIndex = np.load(path+\"/NodeIndex.npy\",allow_pickle = True)\n",
    "print(NodeIndex)\n",
    "print(NodeIndex.shape)\n",
    "print(NodeIndex.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b1dede",
   "metadata": {},
   "outputs": [],
   "source": [
    "AdjacencyMatrix = np.load(path+\"/AdjacencyMatrix.npy\",allow_pickle = True)\n",
    "print(AdjacencyMatrix)\n",
    "print(AdjacencyMatrix.shape)\n",
    "print(AdjacencyMatrix.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bc45b7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# +\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from torch.nn.functional import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ba3538",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ['150', '150R', '149', '1', '2', '3', '7', '4', '5', '6', '8', '12',\n",
    "'9', '13', '9R', '14', '34', '18', '11', '10', '15', '16', '17', '19',\n",
    "'21', '20', '22', '23', '24', '25', '25R', '26', '28', '27', '31',\n",
    "'33', '29', '30', '250', '32', '35', '36', '40', '37', '38', '39',\n",
    "'41', '42', '43', '44', '45', '47', '46', '48', '49', '50', '51',\n",
    "'151', '52', '53', '54', '55', '57', '56', '58', '60', '59', '61',\n",
    "'62', '63', '64', '65', '66', '67', '68', '72', '97', '69', '70',\n",
    "'71', '73', '76', '74', '75', '77', '86', '78', '79', '80', '81',\n",
    "'82', '84', '83', '85', '87', '88', '89', '90', '91', '92', '93',\n",
    "'94', '95', '96', '98', '99', '100', '450', '197', '101', '102',\n",
    "'105', '103', '104', '106', '108', '107', '109', '300', '110',\n",
    "'111', '112', '113', '114', '135', '152', '160R', '160', '61S', '610']\n",
    "#encoder = ['SourceBus', '800', '802', '806', '808', '810', '812', '814', '814r', '850',\n",
    "#'816', '818', '824', '820', '822', '826', '828', '830', '854', '832', '858',\n",
    "#'834', '860', '842', '836', '840', '862', '844', '846', '848', '852r', '888', '856', '852', '864', '838', '890']\n",
    "print(encoder)\n",
    "print(len(encoder))\n",
    "#research_paper_decoder = [0,0,1,2,3,4,5,6,6,6,6,7,8,9,10,11,8,12,12,13,14,15,21,15,16,16,16,17,18,18,13,13,19,13,20,22,23]\n",
    "research_paper_decoder = [0,0,0,1,2,3,4,5,6,7,8,9,10,11,10,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,72,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,14,11,61,61,63,119]\n",
    "print(research_paper_decoder)\n",
    "print(len(research_paper_decoder))\n",
    "FaultLocationLabels = value_data[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c541d1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(len(FaultLocationLabels)):\n",
    "    FaultLocationLabels[n]=research_paper_decoder[encoder.index(str(FaultLocationLabels[n]).upper())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f949826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c207a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = FaultLocationLabels.astype(\"int64\")\n",
    "y = torch.from_numpy(y)\n",
    "x = numpy_data.astype(\"float32\")\n",
    "x = torch.from_numpy(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee878a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NodeIndex = NodeIndex.astype(\"int64\")\n",
    "NodeIndex = NodeIndex.T\n",
    "NodeIndex = torch.from_numpy(NodeIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6af1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)\n",
    "print(y.dtype)\n",
    "print(x)\n",
    "print(x.dtype)\n",
    "print(NodeIndex)\n",
    "print(NodeIndex.dtype)\n",
    "#\n",
    "print(x[0])\n",
    "print(normalize(x[0]))\n",
    "#\n",
    "result_translator = np.unique(FaultLocationLabels.astype(\"int64\")).tolist()\n",
    "print()\n",
    "total_data_list = []\n",
    "for n in range(len(x)):\n",
    "    #print(x[n])\n",
    "    #print(y[n])\n",
    "    DataObject = Data(x = x[n], edge_index = NodeIndex, y = y[n], is_undirected = True) #Testing with non-normalized data\n",
    "    #DataObject = Data(x = x[n], edge_index = NodeIndex, y = y[n], is_undirected = True)\n",
    "    DataObject.is_undirected = True\n",
    "    total_data_list.append(DataObject)\n",
    "#print('Y'*888)\n",
    "#print(total_data_list[0].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0023f117",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "#print(f'Dataset: {total_data_list}:')\n",
    "print('===================')\n",
    "print(f'Number of graphs: {len(total_data_list)}')\n",
    "print(f'Number of features: {total_data_list[0].num_features}')\n",
    "#print(f'Number of classes: {total_data_list[0].num_classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654b6a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = total_data_list[0]  # Get the first graph object.\n",
    "#print(data)\n",
    "#print(data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747539f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(NormalizeFeatures(data.x))\n",
    "print(data.x)\n",
    "print('=============================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8366840f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd28dbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "torch.manual_seed(12345)\n",
    "#total_data_list = total_data_list.shuffle()\n",
    "shuffle(total_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331f1433",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = total_data_list[:26000] #9150 is half\n",
    "test_dataset = total_data_list[26000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a494f979",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb9811d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_dataset[0].x)\n",
    "print(test_dataset[0])\n",
    "#print(train_dataset[0].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a70f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in range(len(test_dataset)):\n",
    "    # noise = np.random.normal(1,0.03, size = (37,6)) #0.09 #Uncomment for noise\n",
    "    # noise = noise.astype(\"float32\")\n",
    "    # noise = torch.from_numpy(noise)\n",
    "    # test_dataset[sample].x = noise*test_dataset[sample].x\n",
    "    test_dataset[sample].x = normalize(test_dataset[sample].x)\n",
    "    #print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348f74df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Y'*888)\n",
    "#print(train_dataset[0].x)\n",
    "print(test_dataset[0].x)\n",
    "print(test_dataset[0])\n",
    "##noise = np.random.normal(1,0.09, size = (16,6))\n",
    "##noise = noise.astype(\"float32\")\n",
    "##noise = torch.from_numpy(noise)\n",
    "print('=============================================================')\n",
    "##\n",
    "print(train_dataset[0].x)\n",
    "print(train_dataset[0])\n",
    "#print(train_dataset[0].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4456fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in range(len(train_dataset)):\n",
    "#    noise = np.random.normal(1,0.09, size = (16,6))\n",
    "#    #    noise = np.random.normal(1,0.09, size = (1,96))\n",
    "#    noise = noise.astype(\"float32\")\n",
    "#    noise = torch.from_numpy(noise)\n",
    "##    print(noise)\n",
    "##    X_test[sample] = X_test[sample]*noise[0]\n",
    "#    train_dataset[sample].x = noise*train_dataset[sample].x\n",
    "    train_dataset[sample].x = normalize(train_dataset[sample].x)\n",
    "    #print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1726929a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print('Y'*888)\n",
    "#print(train_dataset[0].x)\n",
    "print(train_dataset[0].x)\n",
    "print(train_dataset[0])\n",
    "##print(noise*test_dataset[0].x)\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce51e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ab0521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC Metric for PyTorch Models\n",
    "#from torcheval.metrics.aggregation.auc import AUC\n",
    "#metric = AUC()\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.nn import Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e9a48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Soft_list = np.array([[]]).reshape((0,120))\n",
    "values_list = np.array([])\n",
    "pred_list = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb5fce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for data in test_loader:\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        pred= out.argmax(dim=1)\n",
    "        softmax = Softmax()\n",
    "        softout = softmax(out)\n",
    "        y = data.y\n",
    "        Soft_list = np.concatenate((Soft_list, softout.numpy()), axis=0)\n",
    "        pred_list = np.concatenate((pred_list, pred.numpy()), axis=0)\n",
    "        # print(Soft_list)\n",
    "        values_list= np.concatenate((values_list, y.numpy()), axis=None)\n",
    "   # print(out)\n",
    "   # print('*'*888)\n",
    "   # print(softout)\n",
    "   # print('*'*888)\n",
    "print(Soft_list)\n",
    "print(Soft_list.shape)\n",
    "print(values_list)\n",
    "print(values_list.shape)\n",
    "print(pred_list)\n",
    "print(pred_list.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eda824",
   "metadata": {},
   "source": [
    "print(\"The Area Under ROC Curve (AUC) =\", roc_auc_score(values_list, Soft_list, multi_class='ovr'))\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"F1 Score =\", f1_score(values_list, pred_list, average = 'macro'))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Testing Accuracy =\",accuracy_score(values_list, pred_list))\n",
    "\n",
    "# Confusion Matrix for PyTorch Models\n",
    "encoder = ['SourceBus', '800', '802', '806', '808', '810', '812', '814', '814r', '850',\n",
    "'816', '818', '824', '820', '822', '826', '828', '830', '854', '832', '858',\n",
    "'834', '860', '842', '836', '840', '862', '844', '846', '848', '852r', '888', '856', '852', '864', '838', '890']\n",
    "print(encoder)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "confusion_mat_labels = [\"Src/800\", \"802\",\"806\",\"808\",\"810\",\"812\",\"814/850/816\",\"818\",\"824/828\",\"820\",\"822\",\"826\",\"830/854\",\"852/832/888\",\"858\",\n",
    "       \"834/842\",\"836/840/862\",\"844\",\"846/848\",\"856\",\"864\",\"860\",\"838\",\"890\"]\n",
    "\n",
    "values_list = values_list.astype(object)\n",
    "pred_list = pred_list.astype(object)\n",
    "\n",
    "for faults in range(24):\n",
    "   pred_list[pred_list==faults] = confusion_mat_labels[faults]\n",
    "   values_list[values_list==faults] = confusion_mat_labels[faults]\n",
    "\n",
    "print(confusion_mat_labels)\n",
    "print(np.unique(values_list))\n",
    "print(np.unique(pred_list))\n",
    "\n",
    "\n",
    "# cm = confusion_matrix(values_list, pred_list, labels=confusion_mat_labels)#, labels=classes\n",
    "# ConfusionMatrixDisplay(cm, display_labels=confusion_mat_labels).plot(xticks_rotation = 35).ax_.set_title(\"Cheb GCN Confusion Matrix\")\n",
    "# plt.show()\n",
    "cm = confusion_matrix(values_list, pred_list,  labels=confusion_mat_labels)#, labels=classes\n",
    "cmp = ConfusionMatrixDisplay(cm, display_labels=confusion_mat_labels)#.plot(xticks_rotation = 35)#.ax_.set_title(\"kNN Confusion Matrix\")\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "#ax.set_xticks(xtick_labels-12)\n",
    "cmp.plot(ax=ax, xticks_rotation = 40)\n",
    "plt.xticks(np.arange(len(confusion_mat_labels)), confusion_mat_labels, ha='right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# -\n",
    "\n",
    "print(model.state_dict())\n",
    "torch.save(model.state_dict(), 'model_2.pt')\n",
    "# torch.save(model, 'entire_model.pt')\n",
    "\n",
    "cm = confusion_matrix(values_list, pred_list,  labels=confusion_mat_labels)#, labels=classes\n",
    "cmp = ConfusionMatrixDisplay(cm, display_labels=confusion_mat_labels)#.plot(xticks_rotation = 35)#.ax_.set_title(\"kNN Confusion Matrix\")\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "#ax.set_xticks(xtick_labels-12)\n",
    "cmp.plot(ax=ax, xticks_rotation = 40)\n",
    "plt.xticks(np.arange(len(confusion_mat_labels)), confusion_mat_labels, ha='right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
