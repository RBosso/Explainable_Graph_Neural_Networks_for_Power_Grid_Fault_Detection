{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mv5gkpO1ETiy",
    "outputId": "7e9716c0-e2f6-4171-b538-13cb5bd53ea2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_geometric\n",
      "  Downloading torch_geometric-2.5.3-py3-none-any.whl.metadata (64 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.5)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.13.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.10.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.3.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.7.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.5.0)\n",
      "Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch_geometric\n",
      "Successfully installed torch_geometric-2.5.3\n",
      "Collecting captum\n",
      "  Downloading captum-0.7.0-py3-none-any.whl.metadata (26 kB)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from captum) (3.7.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from captum) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from captum) (2.4.0+cu121)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from captum) (4.66.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (1.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2024.6.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->captum) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->captum) (1.3.0)\n",
      "Downloading captum-0.7.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: captum\n",
      "Successfully installed captum-0.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_geometric\n",
    "!pip install captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "bRGWihdzAJTh",
    "outputId": "ecb83705-c276-4163-db42-917cc7d269e8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-71bd7fff-bb3e-451d-b0ca-f495a78cbbdc\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-71bd7fff-bb3e-451d-b0ca-f495a78cbbdc\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving numpy_data.zip to numpy_data.zip\n",
      "Saving model_123.pt to model_123.pt\n",
      "Archive:  numpy_data.zip\n",
      "  inflating: AdjacencyMatrix.npy     \n",
      "  inflating: new_data.npy            \n",
      "  inflating: new_labels.npy          \n",
      "  inflating: NodeIndex.npy           \n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.upload()\n",
    "\n",
    "#jupytext --to ipynb Comparative_Cheb_GCN.py\n",
    "# Don't forget to upload model as well\n",
    "!unzip numpy_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K0Vz4ToaEXxk",
    "outputId": "e4b214d1-1885-41a9-abce-7caea6e163fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): ChebConv(6, 256, K=3, normalization=sym)\n",
      "  (conv2): ChebConv(256, 256, K=4, normalization=sym)\n",
      "  (conv3): ChebConv(256, 256, K=5, normalization=sym)\n",
      "  (lin): Linear(in_features=256, out_features=120, bias=True)\n",
      ")\n",
      "/content/model_123.pt\n",
      "ChebConv(256, 256, K=5, normalization=sym)\n",
      "OrderedDict([('conv1.bias', tensor([ 0.0560, -0.0923,  0.0211,  0.1891, -0.3570, -0.0243, -0.0082, -0.0498,\n",
      "        -0.2476, -0.2073, -0.1551,  0.0744,  0.0436, -0.0038, -0.1946, -0.2249,\n",
      "         0.1485,  0.0596, -0.1403, -0.0865, -0.0554, -0.0322, -0.1644, -0.2891,\n",
      "        -0.0723, -0.0622,  0.1296, -0.3368, -0.0972,  0.0546, -0.4115, -0.0499,\n",
      "         0.0018,  0.0772, -0.0011, -0.3186, -0.0530, -0.0161,  0.1959,  0.0350,\n",
      "        -0.1036, -0.3501,  0.0229, -0.0258, -0.1350, -0.0788,  0.0172,  0.1075,\n",
      "         0.1067,  0.0942,  0.0376,  0.2836, -0.0751, -0.0666,  0.1361, -0.1322,\n",
      "        -0.0099, -0.0077,  0.1709, -0.1765, -0.3071, -0.5233,  0.0284,  0.0188,\n",
      "        -0.1241,  0.0721,  0.0533, -0.0854, -0.0550, -0.2129, -0.0472,  0.1192,\n",
      "        -0.0106, -0.2066, -0.0488, -0.3641, -0.2822,  0.0808, -0.1422, -0.0845,\n",
      "        -0.1749, -0.0133, -0.1458,  0.0116, -0.2085, -0.2896,  0.2951,  0.0570,\n",
      "         0.0163, -0.0687,  0.0168, -0.0076,  0.0672,  0.2268,  0.0403, -0.2853,\n",
      "         0.1414, -0.1342,  0.0881, -0.0883, -0.1912,  0.1624,  0.1357,  0.0572,\n",
      "         0.0880, -0.1306,  0.0637,  0.1958, -0.0364, -0.0214, -0.3526, -0.1502,\n",
      "         0.1457, -0.2079, -0.0862,  0.0313, -0.1342, -0.1982, -0.0403, -0.1308,\n",
      "         0.1088, -0.0779,  0.0729, -0.3599,  0.0264, -0.0482, -0.3490,  0.0175,\n",
      "         0.2454, -0.0732, -0.0476, -0.0627, -0.0795,  0.0453,  0.0144, -0.0056,\n",
      "         0.0084, -0.0766,  0.0751,  0.0690, -0.1862,  0.2744,  0.0443, -0.1969,\n",
      "         0.0726, -0.1227, -0.1002, -0.2278, -0.0121, -0.1022, -0.2068,  0.0463,\n",
      "        -0.0968, -0.0334,  0.0110, -0.1938,  0.0066, -0.0685,  0.0784, -0.0255,\n",
      "         0.0347,  0.2181, -0.2511,  0.1862, -0.0997, -0.0603, -0.2490, -0.2804,\n",
      "         0.0479,  0.0723, -0.0344,  0.1192, -0.3163,  0.1766, -0.2126,  0.0949,\n",
      "        -0.0613, -0.5016, -0.1300,  0.0724, -0.1237, -0.3453,  0.1150, -0.2938,\n",
      "        -0.0567,  0.0620, -0.0202, -0.0155,  0.0887, -0.0199,  0.0345,  0.0911,\n",
      "         0.0819, -0.2550, -0.0367,  0.0750, -0.1915, -0.0770, -0.1298, -0.2909,\n",
      "        -0.0895, -0.0087, -0.1257, -0.0401, -0.0165, -0.0275,  0.0331,  0.0247,\n",
      "        -0.0156, -0.0556,  0.0778, -0.2112,  0.1140,  0.0677, -0.5004,  0.0822,\n",
      "        -0.0517,  0.2783, -0.0076,  0.4078, -0.0189, -0.3821, -0.1790,  0.1203,\n",
      "        -0.0529, -0.1425, -0.2353, -0.0133,  0.0927, -0.1142,  0.2089,  0.0748,\n",
      "         0.1005, -0.0112, -0.0726, -0.1009, -0.0975,  0.0222,  0.0353,  0.2133,\n",
      "        -0.1072, -0.0535, -0.0644,  0.0520,  0.1390,  0.0677, -0.2913, -0.0109,\n",
      "         0.0460, -0.0569,  0.0184, -0.0365,  0.0339,  0.0079,  0.0158, -0.1069])), ('conv1.lins.0.weight', tensor([[ 1.5177e-01,  1.0156e-01, -7.6334e-01, -1.3593e-01,  2.8558e-01,\n",
      "          1.3526e-01],\n",
      "        [-2.4990e-01, -4.3298e-01,  3.2311e-02,  9.9393e-01, -2.1623e-01,\n",
      "          9.6487e-01],\n",
      "        [ 6.7878e-02,  9.8573e-01, -2.3710e+00,  5.0209e-01, -2.4979e-01,\n",
      "         -1.2562e+00],\n",
      "        ...,\n",
      "        [ 1.4806e-01, -9.2365e-01,  9.5834e-02, -6.8868e-02, -1.1837e-01,\n",
      "         -2.3329e+00],\n",
      "        [-8.1544e-01,  6.8232e-01, -5.4271e-01, -4.8825e-01, -3.6590e-01,\n",
      "         -1.5735e-01],\n",
      "        [-2.5154e-01,  2.1808e-03, -2.5333e-01, -1.5040e-01, -2.8333e-01,\n",
      "         -4.6344e-01]])), ('conv1.lins.1.weight', tensor([[-0.1661, -0.0858,  0.9005,  0.4770, -0.1909, -0.1845],\n",
      "        [ 0.3188,  0.8214,  0.0656, -1.0982,  0.1211, -0.9688],\n",
      "        [-0.0986, -0.6502,  1.1769, -1.7176, -0.0296,  0.4025],\n",
      "        ...,\n",
      "        [-0.1792,  1.0935, -0.0671, -0.0165,  0.1724,  2.2140],\n",
      "        [ 0.0654, -0.4071, -0.2010,  0.4810,  0.2996,  0.3520],\n",
      "        [ 0.0913,  0.7000,  0.2413, -0.2235, -0.0130,  0.3768]])), ('conv1.lins.2.weight', tensor([[ 0.1386,  0.3113, -0.9141, -0.6474, -0.0709,  0.4227],\n",
      "        [-0.0049, -0.7800,  0.0545,  0.4780, -0.1528,  0.8001],\n",
      "        [ 0.2829,  0.7631, -0.7390,  2.0834,  0.2071, -0.1729],\n",
      "        ...,\n",
      "        [ 0.1440, -0.8452,  0.0837, -0.3210, -0.2174, -1.3806],\n",
      "        [ 0.3253, -0.8296,  0.2408, -0.2290, -0.0727, -0.1236],\n",
      "        [-0.0063, -1.0166, -0.4244,  0.0877,  0.2109, -0.1416]])), ('conv2.bias', tensor([-0.0984, -0.2463, -0.0390,  0.4573, -0.0487, -0.2330, -0.0534, -0.1076,\n",
      "         0.4649,  0.2663,  0.1374,  0.0114, -0.0559,  0.2440, -0.0393,  0.0429,\n",
      "        -0.0157, -0.1092, -0.0526, -0.5261, -0.5845, -0.3570, -0.0418, -0.1962,\n",
      "         0.3184, -0.9269,  0.0708, -0.3127, -0.0577, -0.2314,  0.2171, -0.4638,\n",
      "        -0.0428, -0.3258, -0.0352,  0.2985,  0.5402,  0.2579,  0.3554, -0.0437,\n",
      "        -0.6029,  0.5377,  0.0131, -0.0112, -0.3449, -0.0177, -0.0158,  0.2013,\n",
      "        -0.2528, -0.2018,  0.0279,  0.0105, -0.1202, -0.2814, -0.2891, -0.5068,\n",
      "        -0.6580,  0.4146, -0.1189,  0.3777, -0.2405, -0.0577, -0.0329, -0.0530,\n",
      "        -0.0187, -0.1115, -0.2532, -0.2800,  0.3309, -0.7152,  0.3358, -0.2554,\n",
      "         0.1428, -0.2622, -0.1908, -0.6596,  0.2331,  0.2271, -0.1948,  0.2518,\n",
      "        -0.3705, -0.5137, -0.0359, -0.8440, -0.0656,  0.1816, -0.0232,  0.3298,\n",
      "        -0.2379, -0.2809, -0.0384,  0.5258, -0.3499, -0.1939,  0.1360, -0.5117,\n",
      "        -0.0438,  0.0475, -0.1872,  0.0193,  0.0629, -0.3980, -0.3945,  0.1108,\n",
      "        -0.1328, -0.0674, -0.0616, -0.0658,  0.3786, -0.2684, -0.5102, -0.0019,\n",
      "        -0.0151,  0.0877, -0.3428, -0.0302, -0.1360, -0.0262,  0.3421,  0.1630,\n",
      "        -0.0111, -0.0331, -0.0495, -0.0335, -0.3696,  0.0183, -0.6453,  0.4595,\n",
      "        -0.0323, -0.1677, -0.3953,  0.0764, -0.7571, -0.5940, -0.5843, -0.0103,\n",
      "        -0.5812, -0.0446, -0.2101,  0.2767, -0.0539, -0.3817,  0.2807, -0.3985,\n",
      "        -0.0529,  0.3192, -0.1596,  0.0185, -0.0702, -0.5432,  0.3847,  0.4361,\n",
      "        -0.0270, -0.1597, -0.0775, -0.0581, -0.1387, -0.6979,  0.6203, -0.2688,\n",
      "        -0.3966, -0.0824, -0.4459, -0.4514, -0.0740, -0.4215, -0.0719, -0.3915,\n",
      "        -0.2776, -0.0533, -0.0251, -0.6775, -0.1719, -0.4812, -0.4095,  0.0379,\n",
      "        -0.0323,  0.0090, -0.0382, -0.0480, -0.0255,  0.5356, -0.9245,  0.1997,\n",
      "        -0.2583, -0.1653,  0.0676,  0.2777,  0.1037, -0.1886, -0.0294,  0.2783,\n",
      "        -0.3795, -0.5563, -0.5944, -0.0548,  0.0094, -0.1324, -0.1162, -0.0562,\n",
      "        -0.1540, -0.8783, -0.0308, -0.0524, -0.2703, -0.4663,  0.0016, -0.0804,\n",
      "        -0.0109, -0.1078, -0.0847, -0.0388, -0.1658,  0.0473, -0.2371, -0.0322,\n",
      "        -0.2314, -0.2742, -0.2932, -0.1428, -0.0927, -0.0718, -0.6044, -0.0327,\n",
      "        -0.1865, -0.0178, -0.0393, -0.5868,  0.0714, -0.0086, -0.0129,  0.0073,\n",
      "        -0.1681, -0.0324, -0.0752,  0.0567, -0.1516, -0.1517, -0.1187, -0.2996,\n",
      "        -0.0462, -0.3351, -0.2920, -0.3693, -0.4178,  0.1835, -0.1384, -0.0569,\n",
      "         0.1606,  0.4804, -0.1415,  0.0294, -0.0185, -0.2909,  0.1779,  0.0105])), ('conv2.lins.0.weight', tensor([[ 0.4939, -0.7496, -0.0861,  ..., -0.4942, -0.0333, -0.2537],\n",
      "        [-0.1164, -0.6365, -0.0456,  ...,  0.4835, -0.3375, -0.3871],\n",
      "        [ 0.0419,  0.0555, -0.0572,  ..., -0.0209, -0.0271,  0.0963],\n",
      "        ...,\n",
      "        [ 0.0182, -0.2896, -0.1582,  ..., -0.8209,  0.0749, -0.7549],\n",
      "        [-0.2123, -0.2808, -0.1233,  ...,  0.1768,  0.1259, -0.0345],\n",
      "        [-0.2698, -0.6934, -0.8748,  ..., -0.2558, -0.1734, -0.6438]])), ('conv2.lins.1.weight', tensor([[-0.2908,  0.9609,  0.1662,  ...,  0.7794, -0.0368,  0.6521],\n",
      "        [ 0.1446,  0.6257,  0.0433,  ..., -0.2694,  0.2783,  0.1478],\n",
      "        [ 0.0689, -0.0829,  0.0177,  ...,  0.0388, -0.0297, -0.0312],\n",
      "        ...,\n",
      "        [-0.0591,  0.0377,  0.1246,  ...,  0.7196,  0.5927,  0.2655],\n",
      "        [ 0.2697,  0.2862,  0.3035,  ..., -0.3626,  0.0187,  0.0922],\n",
      "        [ 0.4690,  0.2913,  0.0591,  ...,  0.1571, -0.0505,  0.1572]])), ('conv2.lins.2.weight', tensor([[ 5.0465e-01, -7.4811e-01,  3.0969e-01,  ..., -3.9177e-01,\n",
      "          7.1665e-02, -3.9136e-01],\n",
      "        [-2.4611e-01, -5.5381e-01, -2.2918e-01,  ...,  1.2035e-01,\n",
      "         -5.4716e-02,  2.5222e-01],\n",
      "        [ 1.3195e-02, -4.9321e-02,  8.4569e-03,  ...,  2.7702e-04,\n",
      "          2.9655e-02,  4.9141e-02],\n",
      "        ...,\n",
      "        [ 8.0940e-02,  2.1729e-01,  3.2514e-02,  ..., -3.3806e-01,\n",
      "         -9.6854e-01, -7.1535e-02],\n",
      "        [-1.8279e-01, -5.0849e-01, -3.9987e-01,  ...,  3.4043e-01,\n",
      "          3.7179e-02, -2.0512e-01],\n",
      "        [-1.2088e-01, -3.0700e-02,  6.3144e-01,  ...,  3.4965e-02,\n",
      "          3.9726e-01, -1.7736e-02]])), ('conv2.lins.3.weight', tensor([[-0.3871, -0.3826, -0.1461,  ...,  0.2138, -0.0492, -0.7789],\n",
      "        [ 0.1051,  0.4311,  0.2303,  ..., -0.2027, -0.3038, -0.2014],\n",
      "        [ 0.0240,  0.0941, -0.0428,  ..., -0.0627,  0.0292, -0.0767],\n",
      "        ...,\n",
      "        [ 0.0563, -0.2970, -0.0336,  ...,  0.0082,  0.7103, -0.4579],\n",
      "        [-0.0889,  0.6439,  0.0972,  ..., -0.3076,  0.2875,  0.0771],\n",
      "        [ 0.2221, -0.0040, -0.1171,  ..., -0.3181, -0.1161,  0.1488]])), ('conv3.bias', tensor([ 0.2674, -0.1991, -0.1117, -0.1736, -0.0096,  0.0315, -0.3468, -0.1111,\n",
      "        -0.2628,  0.2953, -0.1881, -0.0569, -0.2328, -0.2959, -0.2161,  0.0272,\n",
      "        -0.0836,  0.2481, -0.1154, -0.0580, -0.0277, -0.3358, -0.1898,  0.0730,\n",
      "        -0.1730, -0.0419, -0.1798, -0.0647, -0.3422,  0.0016,  0.0334, -0.7493,\n",
      "         0.1706, -0.1756, -0.5465, -0.1696, -0.1574, -0.0305,  0.2243, -0.2510,\n",
      "        -0.1820, -0.2055, -0.1559, -0.0269, -0.2438, -0.0245, -0.0322, -0.0510,\n",
      "        -0.1108, -0.0501, -0.0761,  0.0450,  0.0091, -0.1910,  0.1306, -0.0516,\n",
      "        -0.2627,  0.1027, -0.1365,  0.1348,  0.1020,  0.2032, -0.2849, -0.0714,\n",
      "        -0.2550,  0.0387, -0.0561, -0.1948, -0.1381, -0.2985, -0.1645, -0.0447,\n",
      "         0.0116,  0.0785, -0.7004, -0.1268, -0.4925,  0.1161, -0.0811,  0.0439,\n",
      "        -0.0652, -0.0220, -0.2346, -0.1558, -0.1615, -0.2554,  0.1255, -0.1691,\n",
      "        -0.0343, -0.0373,  0.0138, -0.1274,  0.1049,  0.1387,  0.0879,  0.1162,\n",
      "         0.1184, -0.3887,  0.0276, -0.3005,  0.1149, -0.1342, -0.1363, -0.0370,\n",
      "        -0.2258, -0.2223,  0.0491,  0.0572, -0.0354, -0.2704, -0.4292, -0.0257,\n",
      "         0.2999, -0.2957,  0.2032, -0.1508,  0.1484, -0.2331, -0.1344,  0.1918,\n",
      "         0.2053, -0.2130, -0.1927,  0.2771,  0.1927,  0.1028, -0.7706,  0.0688,\n",
      "        -0.3028, -0.1485,  0.2331, -0.0093, -0.1251, -0.3670, -0.0442, -0.0568,\n",
      "        -0.1033, -0.1690, -0.1097, -0.2431,  0.1976, -0.0464,  0.2500,  0.0279,\n",
      "         0.0559, -0.3056, -0.1147,  0.2105, -0.1848,  0.3881,  0.4072,  0.1367,\n",
      "        -0.2994, -0.2356, -0.4661, -0.3354,  0.0521, -0.2942, -0.0704,  0.0823,\n",
      "        -0.1055, -0.1682, -0.3687, -0.1224, -0.0208, -0.2144, -0.2090, -0.7737,\n",
      "         0.0230, -0.2719, -0.0390,  0.3349,  0.0721,  0.0102, -0.2225,  0.2395,\n",
      "        -0.0233,  0.0521, -0.6733,  0.0664, -0.1759,  0.0699, -0.1490,  0.1236,\n",
      "        -0.1882, -0.1271, -0.1633, -0.3126,  0.2382, -0.0220, -0.0800,  0.2059,\n",
      "         0.2747,  0.0030, -0.3763, -0.0771,  0.1386, -0.1728, -0.0393,  0.1654,\n",
      "        -0.1452, -0.2607,  0.2877, -0.2273, -0.0179,  0.1787,  0.1597, -0.0155,\n",
      "        -0.1202,  0.1861,  0.2670, -0.2669, -0.1798, -0.2054, -0.5312, -0.0125,\n",
      "        -0.0298,  0.3522,  0.1445, -0.6717, -0.6355, -0.4533, -0.1084,  0.1791,\n",
      "        -0.5221, -0.2801, -0.2898, -0.0940,  0.3695, -0.0811, -0.0344,  0.1850,\n",
      "         0.2242, -0.3709, -0.1558,  0.1944,  0.0168, -0.0415, -0.0172,  0.0808,\n",
      "        -0.1927, -0.3680, -0.0204,  0.0212, -0.0120,  0.1422,  0.2406,  0.0282,\n",
      "        -0.0749, -0.0254, -0.4160,  0.1811, -0.1069,  0.1906, -0.0121, -0.0976])), ('conv3.lins.0.weight', tensor([[ 3.6900e-01,  1.0246e-01,  8.6236e-02,  ...,  4.0550e-01,\n",
      "         -1.2893e-01, -5.3203e-01],\n",
      "        [ 1.2432e-03, -4.4420e-01, -2.9962e-02,  ...,  1.2478e-01,\n",
      "         -4.4886e-01,  6.5884e-01],\n",
      "        [ 1.6177e-02, -4.0685e-02, -1.0237e-01,  ..., -2.1039e-01,\n",
      "         -1.0285e-01,  1.8455e-01],\n",
      "        ...,\n",
      "        [-1.1357e+00, -1.0552e+00,  4.9710e-02,  ..., -1.2923e+00,\n",
      "         -3.2561e-01,  1.4099e+00],\n",
      "        [ 3.3878e-01,  1.7431e-01,  4.1741e-02,  ...,  2.4475e-01,\n",
      "         -2.6516e-01, -8.1005e-01],\n",
      "        [ 4.2887e-01, -1.1142e-01, -1.0279e-01,  ...,  8.4048e-01,\n",
      "          1.7358e-01, -3.4330e-01]])), ('conv3.lins.1.weight', tensor([[-0.3256, -0.0701,  0.0141,  ...,  0.0274,  0.2219,  0.5163],\n",
      "        [ 0.2517,  0.7836,  0.0473,  ..., -0.0085,  0.4728, -1.0332],\n",
      "        [-0.1048,  0.0346,  0.0602,  ...,  0.1936,  0.0418, -0.0068],\n",
      "        ...,\n",
      "        [ 0.2495,  1.1938, -0.0200,  ...,  1.9058,  0.0371,  0.1989],\n",
      "        [-0.4118, -0.2974,  0.0535,  ..., -0.2271,  0.2748,  0.6129],\n",
      "        [-0.5874,  0.1441, -0.0535,  ..., -0.7052, -0.1908,  0.5019]])), ('conv3.lins.2.weight', tensor([[ 0.0973, -0.3372, -0.0326,  ..., -0.6188, -0.2932, -0.8283],\n",
      "        [-0.5375, -0.4302,  0.0291,  ..., -0.3419, -0.5132,  0.7206],\n",
      "        [ 0.0467, -0.2025,  0.0389,  ..., -0.2306, -0.1341,  0.0728],\n",
      "        ...,\n",
      "        [-0.0105, -0.7453,  0.0320,  ..., -1.9623,  0.3718, -0.2330],\n",
      "        [ 0.4249,  0.1693, -0.0122,  ...,  0.2606, -0.2753, -0.5378],\n",
      "        [ 0.5870,  0.0573, -0.0143,  ...,  0.4372,  0.1434, -0.4762]])), ('conv3.lins.3.weight', tensor([[ 0.0932,  0.4541, -0.0964,  ..., -0.2119,  0.1801, -0.0662],\n",
      "        [ 0.7888, -0.0197,  0.0113,  ...,  0.4979,  0.3091, -0.3034],\n",
      "        [-0.1715,  0.0577,  0.0566,  ...,  0.2753,  0.2519, -0.1337],\n",
      "        ...,\n",
      "        [ 0.9470,  0.1082, -0.0713,  ...,  1.0661, -0.5712, -1.1885],\n",
      "        [-0.4866, -0.1114, -0.0324,  ..., -0.1232,  0.1689,  0.8726],\n",
      "        [-0.3231, -0.1822,  0.0159,  ..., -0.0667, -0.0076,  0.8097]])), ('conv3.lins.4.weight', tensor([[-0.3479, -0.4100,  0.0579,  ...,  0.0987,  0.1547,  0.3634],\n",
      "        [-0.8488,  0.3219, -0.0498,  ..., -0.4401, -0.0409,  0.0697],\n",
      "        [-0.0403, -0.1728, -0.0966,  ...,  0.0376, -0.2973,  0.0237],\n",
      "        ...,\n",
      "        [ 0.3840,  0.3223,  0.0182,  ..., -0.7565,  0.5214,  0.3786],\n",
      "        [ 0.4476, -0.0963, -0.0594,  ...,  0.2065, -0.2753, -0.9073],\n",
      "        [ 0.0684,  0.3820, -0.0701,  ...,  0.0129, -0.1013, -0.3707]])), ('lin.weight', tensor([[-3.6596,  0.0132, -0.4186,  ...,  0.1156, -0.7892, -0.4100],\n",
      "        [-0.2765,  0.4233,  0.3334,  ..., -6.9651, -0.1805, -0.0487],\n",
      "        [-0.0949,  0.1139, -0.0862,  ..., -0.3234, -1.5269,  0.2205],\n",
      "        ...,\n",
      "        [ 1.1239, -1.3264, -0.2047,  ...,  0.2774, -2.1515, -1.0594],\n",
      "        [-0.7823,  0.6549, -0.1688,  ...,  0.2462, -3.2773,  0.2412],\n",
      "        [-1.7987,  1.4346, -0.1167,  ...,  0.7708, -1.6951, -2.9998]])), ('lin.bias', tensor([ 0.7759,  0.5170, -0.5317, -0.1725,  0.1033, -0.4011, -0.3650, -0.6043,\n",
      "        -1.0021, -0.3011, -0.4152,  0.0577,  0.6019, -0.3118, -0.6133,  0.1968,\n",
      "         0.0968, -0.0924, -0.0369,  0.1895, -0.4834, -0.1937, -0.6405, -0.5041,\n",
      "        -0.0389, -0.5259, -0.4285, -0.0525, -0.1894, -0.1391, -0.0121, -0.3104,\n",
      "        -0.3038,  0.0511,  0.6477, -0.0943, -0.2708,  0.0846, -0.4021, -0.6383,\n",
      "         0.0192, -0.9504, -0.7237, -0.4566, -0.3064, -0.3654,  0.0615, -0.6226,\n",
      "        -0.4979,  0.6506, -0.0609,  0.1940,  0.5938,  0.2589, -0.3897, -0.3390,\n",
      "         0.2490, -0.2607,  0.2549,  0.4781, -0.4360, -0.0034, -0.7708,  0.0136,\n",
      "        -0.3057,  0.0373, -0.4757,  0.0082,  1.1209, -0.1917, -0.0889, -0.2908,\n",
      "        -0.1572, -0.1478, -0.3222, -0.0939,  0.1098, -0.3925,  0.0657, -0.0830,\n",
      "        -0.6816, -0.6992,  0.1104,  0.2147, -0.1373,  0.2451,  0.0679, -0.1188,\n",
      "         0.5686, -0.2142, -0.3881, -0.4171, -0.2828, -0.1460,  0.0195, -0.3623,\n",
      "         0.5781,  0.0268,  0.9469, -0.0285, -0.3745, -0.2629,  0.0626,  0.4154,\n",
      "        -0.1058, -0.0642, -0.2520, -0.0410, -0.1634, -0.0759,  0.0464, -0.8952,\n",
      "        -0.0688,  0.1159, -0.3464, -0.6479,  0.2659,  0.2099, -0.0020,  0.7270]))])\n",
      "2.4.0+cu121\n",
      "/content\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-f9d492e4c8c1>:96: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_save_location, map_location=torch.device('cpu')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "torch.float32\n",
      "5603\n",
      "71\n",
      "4\n",
      "69\n",
      "69\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5604\n",
      "71\n",
      "1\n",
      "65\n",
      "65\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5605\n",
      "71\n",
      "1\n",
      "71\n",
      "71\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5606\n",
      "71\n",
      "1\n",
      "68\n",
      "68\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5607\n",
      "71\n",
      "1\n",
      "4\n",
      "4\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5608\n",
      "71\n",
      "1\n",
      "59\n",
      "59\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5609\n",
      "71\n",
      "1\n",
      "85\n",
      "85\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5610\n",
      "71\n",
      "1\n",
      "101\n",
      "101\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5611\n",
      "71\n",
      "1\n",
      "52\n",
      "52\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5612\n",
      "71\n",
      "1\n",
      "90\n",
      "90\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5613\n",
      "71\n",
      "1\n",
      "0\n",
      "0\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5614\n",
      "71\n",
      "1\n",
      "1\n",
      "1\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5615\n",
      "71\n",
      "1\n",
      "113\n",
      "113\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5616\n",
      "71\n",
      "1\n",
      "33\n",
      "33\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5617\n",
      "71\n",
      "1\n",
      "119\n",
      "119\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5618\n",
      "71\n",
      "1\n",
      "81\n",
      "81\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5619\n",
      "71\n",
      "1\n",
      "110\n",
      "110\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5620\n",
      "71\n",
      "1\n",
      "77\n",
      "77\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5621\n",
      "71\n",
      "38\n",
      "33\n",
      "33\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5622\n",
      "71\n",
      "1\n",
      "0\n",
      "0\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5623\n",
      "71\n",
      "1\n",
      "77\n",
      "77\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5624\n",
      "71\n",
      "1\n",
      "21\n",
      "21\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5625\n",
      "71\n",
      "1\n",
      "27\n",
      "27\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5626\n",
      "71\n",
      "1\n",
      "77\n",
      "77\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5627\n",
      "71\n",
      "1\n",
      "61\n",
      "61\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5628\n",
      "71\n",
      "1\n",
      "63\n",
      "63\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5629\n",
      "71\n",
      "1\n",
      "113\n",
      "113\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5630\n",
      "71\n",
      "1\n",
      "69\n",
      "69\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5631\n",
      "21\n",
      "1\n",
      "26\n",
      "26\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5632\n",
      "71\n",
      "1\n",
      "101\n",
      "101\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5633\n",
      "71\n",
      "1\n",
      "88\n",
      "88\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5634\n",
      "71\n",
      "1\n",
      "81\n",
      "81\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5635\n",
      "71\n",
      "1\n",
      "63\n",
      "63\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5636\n",
      "71\n",
      "1\n",
      "80\n",
      "80\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5637\n",
      "71\n",
      "4\n",
      "36\n",
      "36\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5638\n",
      "71\n",
      "1\n",
      "113\n",
      "113\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5639\n",
      "71\n",
      "1\n",
      "86\n",
      "86\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5640\n",
      "71\n",
      "1\n",
      "59\n",
      "59\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5641\n",
      "71\n",
      "1\n",
      "90\n",
      "90\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5642\n",
      "71\n",
      "1\n",
      "34\n",
      "34\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5643\n",
      "71\n",
      "1\n",
      "119\n",
      "119\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5644\n",
      "71\n",
      "1\n",
      "28\n",
      "28\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5645\n",
      "71\n",
      "1\n",
      "72\n",
      "72\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5646\n",
      "71\n",
      "1\n",
      "47\n",
      "47\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5647\n",
      "71\n",
      "1\n",
      "34\n",
      "34\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5648\n",
      "71\n",
      "1\n",
      "65\n",
      "65\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5649\n",
      "71\n",
      "1\n",
      "96\n",
      "96\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5650\n",
      "71\n",
      "1\n",
      "58\n",
      "58\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5651\n",
      "71\n",
      "1\n",
      "61\n",
      "61\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5652\n",
      "71\n",
      "1\n",
      "80\n",
      "80\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5653\n",
      "71\n",
      "1\n",
      "102\n",
      "102\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5654\n",
      "71\n",
      "1\n",
      "4\n",
      "4\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5655\n",
      "71\n",
      "1\n",
      "69\n",
      "69\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5656\n",
      "71\n",
      "1\n",
      "33\n",
      "33\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5657\n",
      "71\n",
      "1\n",
      "82\n",
      "82\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5658\n",
      "71\n",
      "1\n",
      "14\n",
      "14\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5659\n",
      "71\n",
      "1\n",
      "56\n",
      "56\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5660\n",
      "71\n",
      "1\n",
      "65\n",
      "65\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5661\n",
      "71\n",
      "1\n",
      "55\n",
      "55\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5662\n",
      "71\n",
      "1\n",
      "109\n",
      "109\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5663\n",
      "71\n",
      "1\n",
      "90\n",
      "90\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5664\n",
      "71\n",
      "1\n",
      "57\n",
      "57\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5665\n",
      "71\n",
      "1\n",
      "113\n",
      "113\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5666\n",
      "71\n",
      "1\n",
      "103\n",
      "103\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5667\n",
      "71\n",
      "1\n",
      "72\n",
      "72\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5668\n",
      "71\n",
      "1\n",
      "119\n",
      "119\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5669\n",
      "71\n",
      "1\n",
      "0\n",
      "0\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5670\n",
      "71\n",
      "1\n",
      "28\n",
      "28\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5671\n",
      "71\n",
      "1\n",
      "24\n",
      "24\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5672\n",
      "71\n",
      "1\n",
      "100\n",
      "100\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5673\n",
      "71\n",
      "1\n",
      "0\n",
      "0\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5674\n",
      "71\n",
      "1\n",
      "63\n",
      "63\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5675\n",
      "71\n",
      "1\n",
      "32\n",
      "32\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5676\n",
      "71\n",
      "1\n",
      "82\n",
      "82\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5677\n",
      "71\n",
      "1\n",
      "37\n",
      "37\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5678\n",
      "71\n",
      "1\n",
      "55\n",
      "55\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5679\n",
      "71\n",
      "1\n",
      "81\n",
      "81\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5680\n",
      "71\n",
      "1\n",
      "56\n",
      "56\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5681\n",
      "71\n",
      "1\n",
      "52\n",
      "52\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5682\n",
      "71\n",
      "1\n",
      "43\n",
      "43\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5683\n",
      "71\n",
      "1\n",
      "86\n",
      "86\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5684\n",
      "71\n",
      "1\n",
      "38\n",
      "38\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5685\n",
      "71\n",
      "1\n",
      "53\n",
      "53\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5686\n",
      "71\n",
      "4\n",
      "54\n",
      "54\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5687\n",
      "71\n",
      "1\n",
      "43\n",
      "43\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5688\n",
      "71\n",
      "1\n",
      "81\n",
      "81\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5689\n",
      "71\n",
      "1\n",
      "84\n",
      "84\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5690\n",
      "71\n",
      "1\n",
      "71\n",
      "71\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5691\n",
      "71\n",
      "1\n",
      "63\n",
      "63\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5692\n",
      "71\n",
      "1\n",
      "11\n",
      "11\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5693\n",
      "71\n",
      "1\n",
      "14\n",
      "14\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5694\n",
      "71\n",
      "1\n",
      "28\n",
      "28\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5695\n",
      "71\n",
      "1\n",
      "64\n",
      "64\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5696\n",
      "71\n",
      "1\n",
      "66\n",
      "66\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5697\n",
      "71\n",
      "1\n",
      "72\n",
      "72\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5698\n",
      "71\n",
      "1\n",
      "8\n",
      "8\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5699\n",
      "71\n",
      "1\n",
      "50\n",
      "50\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5700\n",
      "71\n",
      "1\n",
      "77\n",
      "77\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5701\n",
      "71\n",
      "1\n",
      "54\n",
      "54\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5702\n",
      "71\n",
      "1\n",
      "52\n",
      "52\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5703\n",
      "71\n",
      "1\n",
      "32\n",
      "32\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5704\n",
      "71\n",
      "1\n",
      "89\n",
      "89\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5705\n",
      "71\n",
      "1\n",
      "111\n",
      "111\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5706\n",
      "71\n",
      "1\n",
      "32\n",
      "32\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5707\n",
      "71\n",
      "1\n",
      "49\n",
      "49\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5708\n",
      "71\n",
      "9\n",
      "72\n",
      "72\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5709\n",
      "71\n",
      "22\n",
      "10\n",
      "10\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5710\n",
      "71\n",
      "1\n",
      "63\n",
      "63\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5711\n",
      "71\n",
      "9\n",
      "37\n",
      "37\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5712\n",
      "71\n",
      "9\n",
      "64\n",
      "64\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5713\n",
      "71\n",
      "1\n",
      "103\n",
      "103\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5714\n",
      "71\n",
      "1\n",
      "59\n",
      "59\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5715\n",
      "71\n",
      "1\n",
      "104\n",
      "104\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5716\n",
      "71\n",
      "1\n",
      "71\n",
      "71\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5717\n",
      "71\n",
      "9\n",
      "8\n",
      "8\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5718\n",
      "71\n",
      "1\n",
      "101\n",
      "101\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5719\n",
      "71\n",
      "38\n",
      "24\n",
      "24\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5720\n",
      "71\n",
      "1\n",
      "65\n",
      "65\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5721\n",
      "71\n",
      "1\n",
      "72\n",
      "72\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5722\n",
      "71\n",
      "1\n",
      "77\n",
      "77\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5723\n",
      "71\n",
      "1\n",
      "34\n",
      "34\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5724\n",
      "71\n",
      "1\n",
      "36\n",
      "36\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5725\n",
      "71\n",
      "1\n",
      "63\n",
      "63\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5726\n",
      "71\n",
      "1\n",
      "81\n",
      "81\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5727\n",
      "71\n",
      "1\n",
      "61\n",
      "61\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5728\n",
      "71\n",
      "71\n",
      "116\n",
      "116\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5729\n",
      "71\n",
      "1\n",
      "11\n",
      "11\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5730\n",
      "71\n",
      "1\n",
      "80\n",
      "80\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5731\n",
      "71\n",
      "1\n",
      "72\n",
      "72\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5732\n",
      "71\n",
      "1\n",
      "102\n",
      "102\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5733\n",
      "71\n",
      "9\n",
      "65\n",
      "65\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5734\n",
      "71\n",
      "1\n",
      "48\n",
      "48\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5735\n",
      "71\n",
      "1\n",
      "71\n",
      "71\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5736\n",
      "71\n",
      "1\n",
      "11\n",
      "11\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5737\n",
      "21\n",
      "1\n",
      "55\n",
      "55\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5738\n",
      "71\n",
      "1\n",
      "119\n",
      "119\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5739\n",
      "71\n",
      "1\n",
      "1\n",
      "1\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5740\n",
      "9\n",
      "1\n",
      "11\n",
      "11\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5741\n",
      "71\n",
      "1\n",
      "86\n",
      "86\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5742\n",
      "71\n",
      "1\n",
      "82\n",
      "80\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5743\n",
      "71\n",
      "1\n",
      "72\n",
      "72\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5744\n",
      "71\n",
      "1\n",
      "22\n",
      "22\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5745\n",
      "9\n",
      "9\n",
      "26\n",
      "26\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5746\n",
      "71\n",
      "9\n",
      "8\n",
      "8\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5747\n",
      "71\n",
      "1\n",
      "63\n",
      "63\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5748\n",
      "71\n",
      "1\n",
      "59\n",
      "59\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5749\n",
      "71\n",
      "1\n",
      "36\n",
      "36\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5750\n",
      "71\n",
      "1\n",
      "72\n",
      "72\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5751\n",
      "71\n",
      "1\n",
      "8\n",
      "8\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5752\n",
      "71\n",
      "1\n",
      "86\n",
      "88\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5753\n",
      "71\n",
      "1\n",
      "67\n",
      "67\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5754\n",
      "71\n",
      "4\n",
      "24\n",
      "24\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5755\n",
      "71\n",
      "38\n",
      "29\n",
      "29\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5756\n",
      "71\n",
      "1\n",
      "63\n",
      "63\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5757\n",
      "71\n",
      "1\n",
      "57\n",
      "57\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5758\n",
      "71\n",
      "1\n",
      "43\n",
      "43\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5759\n",
      "71\n",
      "1\n",
      "60\n",
      "60\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5760\n",
      "71\n",
      "1\n",
      "119\n",
      "119\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5761\n",
      "71\n",
      "1\n",
      "85\n",
      "85\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5762\n",
      "71\n",
      "1\n",
      "0\n",
      "0\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5763\n",
      "71\n",
      "1\n",
      "71\n",
      "71\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5764\n",
      "71\n",
      "1\n",
      "0\n",
      "0\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5765\n",
      "71\n",
      "1\n",
      "33\n",
      "33\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5766\n",
      "21\n",
      "1\n",
      "69\n",
      "69\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5767\n",
      "71\n",
      "1\n",
      "32\n",
      "32\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5768\n",
      "71\n",
      "1\n",
      "110\n",
      "110\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5769\n",
      "71\n",
      "38\n",
      "0\n",
      "0\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5770\n",
      "71\n",
      "1\n",
      "85\n",
      "85\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5771\n",
      "71\n",
      "1\n",
      "43\n",
      "43\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5772\n",
      "71\n",
      "1\n",
      "45\n",
      "45\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5773\n",
      "71\n",
      "38\n",
      "68\n",
      "68\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5774\n",
      "71\n",
      "1\n",
      "100\n",
      "100\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5775\n",
      "71\n",
      "1\n",
      "4\n",
      "4\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5776\n",
      "71\n",
      "1\n",
      "72\n",
      "72\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5777\n",
      "71\n",
      "1\n",
      "88\n",
      "88\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5778\n",
      "71\n",
      "9\n",
      "4\n",
      "4\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5779\n",
      "71\n",
      "1\n",
      "101\n",
      "101\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5780\n",
      "71\n",
      "9\n",
      "11\n",
      "11\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5781\n",
      "71\n",
      "1\n",
      "11\n",
      "11\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5782\n",
      "71\n",
      "1\n",
      "95\n",
      "95\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5783\n",
      "71\n",
      "1\n",
      "1\n",
      "1\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5784\n",
      "71\n",
      "4\n",
      "14\n",
      "14\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5785\n",
      "71\n",
      "1\n",
      "61\n",
      "61\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5786\n",
      "71\n",
      "1\n",
      "61\n",
      "61\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5787\n",
      "71\n",
      "1\n",
      "54\n",
      "54\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5788\n",
      "71\n",
      "1\n",
      "37\n",
      "37\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5789\n",
      "71\n",
      "1\n",
      "106\n",
      "106\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5790\n",
      "71\n",
      "1\n",
      "28\n",
      "28\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5791\n",
      "71\n",
      "1\n",
      "25\n",
      "25\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5792\n",
      "71\n",
      "1\n",
      "33\n",
      "33\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5793\n",
      "71\n",
      "1\n",
      "52\n",
      "52\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5794\n",
      "71\n",
      "1\n",
      "65\n",
      "65\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5795\n",
      "71\n",
      "1\n",
      "98\n",
      "98\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5796\n",
      "71\n",
      "1\n",
      "83\n",
      "83\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5797\n",
      "71\n",
      "1\n",
      "100\n",
      "100\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5798\n",
      "71\n",
      "1\n",
      "14\n",
      "14\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5799\n",
      "71\n",
      "1\n",
      "8\n",
      "8\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5800\n",
      "71\n",
      "1\n",
      "41\n",
      "41\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5801\n",
      "71\n",
      "1\n",
      "4\n",
      "4\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5802\n",
      "71\n",
      "1\n",
      "77\n",
      "77\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5803\n",
      "71\n",
      "1\n",
      "38\n",
      "38\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5804\n",
      "21\n",
      "1\n",
      "26\n",
      "26\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5805\n",
      "71\n",
      "1\n",
      "29\n",
      "29\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5806\n",
      "71\n",
      "1\n",
      "14\n",
      "14\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5807\n",
      "71\n",
      "1\n",
      "93\n",
      "93\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5808\n",
      "71\n",
      "1\n",
      "53\n",
      "53\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5809\n",
      "71\n",
      "1\n",
      "11\n",
      "11\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5810\n",
      "21\n",
      "1\n",
      "36\n",
      "36\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5811\n",
      "71\n",
      "1\n",
      "103\n",
      "103\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5812\n",
      "71\n",
      "1\n",
      "98\n",
      "98\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5813\n",
      "71\n",
      "1\n",
      "95\n",
      "95\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5814\n",
      "71\n",
      "1\n",
      "61\n",
      "61\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5815\n",
      "71\n",
      "1\n",
      "11\n",
      "11\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5816\n",
      "71\n",
      "71\n",
      "74\n",
      "74\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5817\n",
      "71\n",
      "1\n",
      "69\n",
      "69\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5818\n",
      "71\n",
      "1\n",
      "8\n",
      "8\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5819\n",
      "71\n",
      "1\n",
      "77\n",
      "77\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5820\n",
      "71\n",
      "1\n",
      "102\n",
      "102\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5821\n",
      "71\n",
      "1\n",
      "85\n",
      "85\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5822\n",
      "21\n",
      "1\n",
      "72\n",
      "72\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5823\n",
      "71\n",
      "1\n",
      "80\n",
      "80\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5824\n",
      "71\n",
      "1\n",
      "65\n",
      "65\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5825\n",
      "71\n",
      "1\n",
      "1\n",
      "1\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5826\n",
      "71\n",
      "1\n",
      "56\n",
      "56\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5827\n",
      "71\n",
      "1\n",
      "36\n",
      "36\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5828\n",
      "71\n",
      "1\n",
      "72\n",
      "72\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5829\n",
      "71\n",
      "38\n",
      "21\n",
      "21\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5830\n",
      "71\n",
      "1\n",
      "113\n",
      "113\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5831\n",
      "71\n",
      "1\n",
      "103\n",
      "103\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5832\n",
      "71\n",
      "1\n",
      "58\n",
      "58\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5833\n",
      "71\n",
      "1\n",
      "61\n",
      "61\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5834\n",
      "71\n",
      "1\n",
      "55\n",
      "55\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5835\n",
      "71\n",
      "1\n",
      "58\n",
      "58\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5836\n",
      "71\n",
      "1\n",
      "0\n",
      "0\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5837\n",
      "71\n",
      "1\n",
      "61\n",
      "61\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5838\n",
      "71\n",
      "1\n",
      "113\n",
      "113\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5839\n",
      "71\n",
      "1\n",
      "79\n",
      "79\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5840\n",
      "21\n",
      "1\n",
      "11\n",
      "11\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5841\n",
      "71\n",
      "1\n",
      "52\n",
      "52\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5842\n",
      "71\n",
      "1\n",
      "4\n",
      "4\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5843\n",
      "71\n",
      "1\n",
      "101\n",
      "101\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5844\n",
      "71\n",
      "1\n",
      "71\n",
      "71\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5845\n",
      "71\n",
      "1\n",
      "55\n",
      "55\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5846\n",
      "71\n",
      "4\n",
      "57\n",
      "57\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5847\n",
      "71\n",
      "1\n",
      "51\n",
      "51\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5848\n",
      "71\n",
      "1\n",
      "0\n",
      "0\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5849\n",
      "71\n",
      "1\n",
      "69\n",
      "69\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5850\n",
      "71\n",
      "1\n",
      "66\n",
      "66\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5851\n",
      "71\n",
      "1\n",
      "59\n",
      "59\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5852\n",
      "71\n",
      "1\n",
      "32\n",
      "32\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5853\n",
      "71\n",
      "1\n",
      "57\n",
      "57\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5854\n",
      "71\n",
      "1\n",
      "110\n",
      "110\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5855\n",
      "71\n",
      "1\n",
      "28\n",
      "28\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5856\n",
      "71\n",
      "1\n",
      "52\n",
      "52\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5857\n",
      "71\n",
      "9\n",
      "43\n",
      "43\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5858\n",
      "71\n",
      "1\n",
      "86\n",
      "86\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5859\n",
      "71\n",
      "4\n",
      "85\n",
      "85\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5860\n",
      "71\n",
      "1\n",
      "42\n",
      "42\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5861\n",
      "71\n",
      "1\n",
      "85\n",
      "85\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5862\n",
      "71\n",
      "1\n",
      "24\n",
      "24\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5863\n",
      "71\n",
      "1\n",
      "54\n",
      "54\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5864\n",
      "71\n",
      "1\n",
      "4\n",
      "4\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5865\n",
      "71\n",
      "4\n",
      "16\n",
      "15\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5866\n",
      "71\n",
      "1\n",
      "105\n",
      "105\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5867\n",
      "71\n",
      "1\n",
      "47\n",
      "47\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5868\n",
      "71\n",
      "1\n",
      "63\n",
      "63\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5869\n",
      "71\n",
      "9\n",
      "8\n",
      "8\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5870\n",
      "71\n",
      "9\n",
      "28\n",
      "28\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5871\n",
      "71\n",
      "1\n",
      "57\n",
      "57\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5872\n",
      "71\n",
      "1\n",
      "53\n",
      "53\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5873\n",
      "71\n",
      "1\n",
      "107\n",
      "107\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5874\n",
      "71\n",
      "9\n",
      "55\n",
      "55\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5875\n",
      "21\n",
      "1\n",
      "56\n",
      "56\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5876\n",
      "71\n",
      "1\n",
      "94\n",
      "94\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5877\n",
      "71\n",
      "1\n",
      "52\n",
      "52\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5878\n",
      "71\n",
      "1\n",
      "72\n",
      "72\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5879\n",
      "21\n",
      "1\n",
      "1\n",
      "1\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5880\n",
      "71\n",
      "80\n",
      "119\n",
      "119\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5881\n",
      "71\n",
      "1\n",
      "51\n",
      "51\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5882\n",
      "71\n",
      "4\n",
      "112\n",
      "112\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5883\n",
      "71\n",
      "1\n",
      "65\n",
      "65\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5884\n",
      "71\n",
      "1\n",
      "82\n",
      "82\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5885\n",
      "71\n",
      "1\n",
      "100\n",
      "100\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5886\n",
      "71\n",
      "4\n",
      "106\n",
      "106\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5887\n",
      "71\n",
      "1\n",
      "50\n",
      "50\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5888\n",
      "71\n",
      "1\n",
      "0\n",
      "0\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5889\n",
      "71\n",
      "1\n",
      "113\n",
      "113\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5890\n",
      "71\n",
      "1\n",
      "56\n",
      "56\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5891\n",
      "71\n",
      "1\n",
      "100\n",
      "100\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5892\n",
      "71\n",
      "1\n",
      "49\n",
      "49\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5893\n",
      "71\n",
      "1\n",
      "61\n",
      "61\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5894\n",
      "71\n",
      "1\n",
      "92\n",
      "92\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5895\n",
      "71\n",
      "4\n",
      "64\n",
      "64\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5896\n",
      "71\n",
      "1\n",
      "110\n",
      "110\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5897\n",
      "71\n",
      "1\n",
      "53\n",
      "53\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5898\n",
      "71\n",
      "1\n",
      "47\n",
      "47\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5899\n",
      "71\n",
      "1\n",
      "66\n",
      "66\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5900\n",
      "71\n",
      "1\n",
      "47\n",
      "47\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5901\n",
      "71\n",
      "1\n",
      "63\n",
      "63\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5902\n",
      "71\n",
      "1\n",
      "96\n",
      "96\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5903\n",
      "71\n",
      "1\n",
      "61\n",
      "61\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5904\n",
      "71\n",
      "1\n",
      "103\n",
      "103\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5905\n",
      "71\n",
      "1\n",
      "106\n",
      "106\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5906\n",
      "71\n",
      "1\n",
      "80\n",
      "80\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5907\n",
      "71\n",
      "1\n",
      "1\n",
      "1\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5908\n",
      "21\n",
      "1\n",
      "58\n",
      "58\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5909\n",
      "71\n",
      "1\n",
      "4\n",
      "4\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5910\n",
      "71\n",
      "1\n",
      "84\n",
      "84\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5911\n",
      "71\n",
      "4\n",
      "71\n",
      "71\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5912\n",
      "71\n",
      "1\n",
      "83\n",
      "83\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5913\n",
      "71\n",
      "1\n",
      "86\n",
      "86\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5914\n",
      "71\n",
      "1\n",
      "92\n",
      "92\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5915\n",
      "71\n",
      "1\n",
      "90\n",
      "90\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5916\n",
      "71\n",
      "1\n",
      "81\n",
      "81\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5917\n",
      "71\n",
      "1\n",
      "101\n",
      "101\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5918\n",
      "71\n",
      "9\n",
      "36\n",
      "36\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5919\n",
      "71\n",
      "4\n",
      "29\n",
      "29\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5920\n",
      "71\n",
      "1\n",
      "54\n",
      "54\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5921\n",
      "71\n",
      "38\n",
      "72\n",
      "72\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5922\n",
      "71\n",
      "1\n",
      "86\n",
      "86\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5923\n",
      "71\n",
      "38\n",
      "0\n",
      "0\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5924\n",
      "71\n",
      "1\n",
      "38\n",
      "38\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5925\n",
      "71\n",
      "1\n",
      "47\n",
      "47\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5926\n",
      "71\n",
      "1\n",
      "36\n",
      "36\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5927\n",
      "71\n",
      "1\n",
      "65\n",
      "65\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5928\n",
      "71\n",
      "1\n",
      "102\n",
      "102\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5929\n",
      "71\n",
      "1\n",
      "8\n",
      "8\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5930\n",
      "71\n",
      "38\n",
      "83\n",
      "83\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5931\n",
      "21\n",
      "1\n",
      "11\n",
      "11\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5932\n",
      "71\n",
      "1\n",
      "55\n",
      "55\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5933\n",
      "71\n",
      "1\n",
      "56\n",
      "56\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5934\n",
      "71\n",
      "1\n",
      "58\n",
      "58\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5935\n",
      "71\n",
      "1\n",
      "84\n",
      "84\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5936\n",
      "71\n",
      "1\n",
      "0\n",
      "0\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5937\n",
      "71\n",
      "9\n",
      "69\n",
      "69\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5938\n",
      "71\n",
      "1\n",
      "102\n",
      "102\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5939\n",
      "71\n",
      "1\n",
      "21\n",
      "21\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5940\n",
      "71\n",
      "1\n",
      "77\n",
      "77\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5941\n",
      "71\n",
      "1\n",
      "61\n",
      "61\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5942\n",
      "71\n",
      "1\n",
      "84\n",
      "84\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5943\n",
      "71\n",
      "1\n",
      "72\n",
      "72\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5944\n",
      "71\n",
      "1\n",
      "63\n",
      "63\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5945\n",
      "71\n",
      "1\n",
      "54\n",
      "54\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5946\n",
      "71\n",
      "1\n",
      "64\n",
      "64\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5947\n",
      "71\n",
      "4\n",
      "11\n",
      "11\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5948\n",
      "71\n",
      "1\n",
      "72\n",
      "72\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5949\n",
      "71\n",
      "1\n",
      "72\n",
      "72\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5950\n",
      "71\n",
      "1\n",
      "28\n",
      "28\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5951\n",
      "71\n",
      "1\n",
      "67\n",
      "67\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5952\n",
      "71\n",
      "1\n",
      "8\n",
      "8\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5953\n",
      "71\n",
      "1\n",
      "80\n",
      "80\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5954\n",
      "71\n",
      "1\n",
      "101\n",
      "101\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5955\n",
      "71\n",
      "1\n",
      "81\n",
      "81\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5956\n",
      "71\n",
      "1\n",
      "47\n",
      "47\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5957\n",
      "71\n",
      "38\n",
      "66\n",
      "66\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5958\n",
      "71\n",
      "1\n",
      "14\n",
      "14\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5959\n",
      "71\n",
      "4\n",
      "14\n",
      "14\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5960\n",
      "71\n",
      "1\n",
      "96\n",
      "96\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5961\n",
      "71\n",
      "1\n",
      "119\n",
      "119\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5962\n",
      "71\n",
      "1\n",
      "39\n",
      "39\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5963\n",
      "71\n",
      "1\n",
      "45\n",
      "45\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5964\n",
      "71\n",
      "1\n",
      "78\n",
      "78\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5965\n",
      "71\n",
      "1\n",
      "101\n",
      "101\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5966\n",
      "71\n",
      "9\n",
      "106\n",
      "106\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5967\n",
      "71\n",
      "1\n",
      "52\n",
      "52\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5968\n",
      "71\n",
      "38\n",
      "94\n",
      "94\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5969\n",
      "71\n",
      "1\n",
      "57\n",
      "57\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5970\n",
      "71\n",
      "1\n",
      "0\n",
      "0\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5971\n",
      "71\n",
      "1\n",
      "66\n",
      "66\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5972\n",
      "71\n",
      "1\n",
      "15\n",
      "15\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5973\n",
      "71\n",
      "9\n",
      "69\n",
      "69\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5974\n",
      "71\n",
      "4\n",
      "56\n",
      "56\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5975\n",
      "71\n",
      "1\n",
      "92\n",
      "92\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5976\n",
      "71\n",
      "1\n",
      "92\n",
      "94\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5977\n",
      "71\n",
      "1\n",
      "55\n",
      "55\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5978\n",
      "71\n",
      "1\n",
      "13\n",
      "13\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5979\n",
      "71\n",
      "1\n",
      "86\n",
      "86\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5980\n",
      "71\n",
      "1\n",
      "49\n",
      "49\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5981\n",
      "71\n",
      "1\n",
      "71\n",
      "71\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5982\n",
      "71\n",
      "1\n",
      "55\n",
      "55\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5983\n",
      "71\n",
      "1\n",
      "74\n",
      "74\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5984\n",
      "71\n",
      "1\n",
      "59\n",
      "59\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5985\n",
      "71\n",
      "1\n",
      "106\n",
      "106\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5986\n",
      "71\n",
      "1\n",
      "65\n",
      "65\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5987\n",
      "71\n",
      "38\n",
      "47\n",
      "47\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5988\n",
      "71\n",
      "1\n",
      "30\n",
      "30\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5989\n",
      "71\n",
      "1\n",
      "54\n",
      "54\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5990\n",
      "71\n",
      "1\n",
      "95\n",
      "95\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5991\n",
      "71\n",
      "1\n",
      "85\n",
      "85\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5992\n",
      "71\n",
      "1\n",
      "85\n",
      "85\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5993\n",
      "71\n",
      "1\n",
      "89\n",
      "89\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5994\n",
      "71\n",
      "1\n",
      "40\n",
      "40\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5995\n",
      "71\n",
      "1\n",
      "71\n",
      "71\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5996\n",
      "71\n",
      "9\n",
      "61\n",
      "61\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5997\n",
      "71\n",
      "1\n",
      "3\n",
      "3\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5998\n",
      "71\n",
      "1\n",
      "49\n",
      "49\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "5999\n",
      "71\n",
      "1\n",
      "33\n",
      "33\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6000\n",
      "71\n",
      "1\n",
      "38\n",
      "38\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6001\n",
      "71\n",
      "1\n",
      "88\n",
      "88\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6002\n",
      "71\n",
      "1\n",
      "28\n",
      "28\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6003\n",
      "71\n",
      "1\n",
      "11\n",
      "11\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6004\n",
      "71\n",
      "1\n",
      "0\n",
      "0\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6005\n",
      "71\n",
      "1\n",
      "82\n",
      "82\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6006\n",
      "71\n",
      "1\n",
      "0\n",
      "0\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6007\n",
      "71\n",
      "1\n",
      "72\n",
      "72\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6008\n",
      "71\n",
      "1\n",
      "0\n",
      "0\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6009\n",
      "71\n",
      "1\n",
      "21\n",
      "21\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6010\n",
      "71\n",
      "1\n",
      "68\n",
      "68\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6011\n",
      "71\n",
      "1\n",
      "90\n",
      "90\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6012\n",
      "71\n",
      "1\n",
      "83\n",
      "83\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6013\n",
      "71\n",
      "1\n",
      "11\n",
      "11\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6014\n",
      "4\n",
      "1\n",
      "11\n",
      "11\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6015\n",
      "71\n",
      "1\n",
      "82\n",
      "82\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6016\n",
      "71\n",
      "1\n",
      "43\n",
      "43\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6017\n",
      "71\n",
      "1\n",
      "11\n",
      "11\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6018\n",
      "71\n",
      "1\n",
      "81\n",
      "81\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6019\n",
      "71\n",
      "1\n",
      "26\n",
      "26\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6020\n",
      "71\n",
      "1\n",
      "56\n",
      "56\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6021\n",
      "71\n",
      "1\n",
      "61\n",
      "61\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6022\n",
      "71\n",
      "1\n",
      "0\n",
      "0\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6023\n",
      "71\n",
      "1\n",
      "26\n",
      "26\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6024\n",
      "71\n",
      "38\n",
      "16\n",
      "15\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6025\n",
      "71\n",
      "1\n",
      "32\n",
      "32\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6026\n",
      "71\n",
      "1\n",
      "27\n",
      "27\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6027\n",
      "71\n",
      "1\n",
      "83\n",
      "83\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6028\n",
      "71\n",
      "1\n",
      "24\n",
      "24\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6029\n",
      "71\n",
      "1\n",
      "106\n",
      "106\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6030\n",
      "71\n",
      "1\n",
      "104\n",
      "104\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6031\n",
      "71\n",
      "1\n",
      "55\n",
      "55\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6032\n",
      "71\n",
      "1\n",
      "47\n",
      "47\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6033\n",
      "71\n",
      "1\n",
      "27\n",
      "27\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6034\n",
      "9\n",
      "1\n",
      "72\n",
      "72\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6035\n",
      "71\n",
      "1\n",
      "90\n",
      "90\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6036\n",
      "71\n",
      "1\n",
      "65\n",
      "65\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6037\n",
      "71\n",
      "1\n",
      "32\n",
      "32\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6038\n",
      "71\n",
      "9\n",
      "56\n",
      "56\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6039\n",
      "71\n",
      "1\n",
      "38\n",
      "38\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6040\n",
      "71\n",
      "1\n",
      "71\n",
      "71\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6041\n",
      "71\n",
      "1\n",
      "47\n",
      "47\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6042\n",
      "71\n",
      "1\n",
      "53\n",
      "53\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6043\n",
      "71\n",
      "1\n",
      "31\n",
      "31\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6044\n",
      "71\n",
      "1\n",
      "83\n",
      "83\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6045\n",
      "71\n",
      "1\n",
      "98\n",
      "98\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6046\n",
      "71\n",
      "1\n",
      "43\n",
      "43\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6047\n",
      "71\n",
      "1\n",
      "84\n",
      "84\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6048\n",
      "71\n",
      "1\n",
      "81\n",
      "81\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6049\n",
      "71\n",
      "1\n",
      "65\n",
      "65\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6050\n",
      "71\n",
      "1\n",
      "50\n",
      "50\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6051\n",
      "71\n",
      "1\n",
      "36\n",
      "36\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6052\n",
      "71\n",
      "1\n",
      "32\n",
      "32\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6053\n",
      "71\n",
      "1\n",
      "14\n",
      "14\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6054\n",
      "71\n",
      "1\n",
      "59\n",
      "59\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6055\n",
      "71\n",
      "1\n",
      "96\n",
      "96\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6056\n",
      "71\n",
      "1\n",
      "9\n",
      "9\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6057\n",
      "71\n",
      "1\n",
      "90\n",
      "90\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6058\n",
      "71\n",
      "1\n",
      "77\n",
      "77\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6059\n",
      "71\n",
      "1\n",
      "67\n",
      "67\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6060\n",
      "71\n",
      "1\n",
      "106\n",
      "106\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6061\n",
      "71\n",
      "1\n",
      "0\n",
      "0\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6062\n",
      "71\n",
      "1\n",
      "84\n",
      "84\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6063\n",
      "71\n",
      "1\n",
      "86\n",
      "86\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6064\n",
      "71\n",
      "1\n",
      "67\n",
      "67\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6065\n",
      "71\n",
      "1\n",
      "81\n",
      "81\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6066\n",
      "71\n",
      "1\n",
      "56\n",
      "56\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6067\n",
      "71\n",
      "1\n",
      "101\n",
      "101\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6068\n",
      "71\n",
      "9\n",
      "14\n",
      "14\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6069\n",
      "71\n",
      "1\n",
      "45\n",
      "45\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6070\n",
      "71\n",
      "1\n",
      "110\n",
      "110\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6071\n",
      "71\n",
      "1\n",
      "71\n",
      "71\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6072\n",
      "71\n",
      "1\n",
      "92\n",
      "92\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6073\n",
      "71\n",
      "1\n",
      "115\n",
      "115\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6074\n",
      "71\n",
      "1\n",
      "24\n",
      "24\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6075\n",
      "71\n",
      "1\n",
      "28\n",
      "28\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6076\n",
      "71\n",
      "1\n",
      "14\n",
      "14\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6077\n",
      "71\n",
      "1\n",
      "63\n",
      "63\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6078\n",
      "21\n",
      "1\n",
      "11\n",
      "11\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6079\n",
      "71\n",
      "1\n",
      "108\n",
      "108\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6080\n",
      "71\n",
      "1\n",
      "90\n",
      "90\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6081\n",
      "71\n",
      "4\n",
      "71\n",
      "71\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6082\n",
      "71\n",
      "1\n",
      "57\n",
      "57\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6083\n",
      "71\n",
      "1\n",
      "101\n",
      "101\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6084\n",
      "71\n",
      "1\n",
      "4\n",
      "4\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6085\n",
      "71\n",
      "1\n",
      "24\n",
      "24\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6086\n",
      "71\n",
      "1\n",
      "52\n",
      "52\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6087\n",
      "71\n",
      "1\n",
      "72\n",
      "72\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6088\n",
      "21\n",
      "1\n",
      "8\n",
      "8\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6089\n",
      "21\n",
      "1\n",
      "1\n",
      "1\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6090\n",
      "71\n",
      "1\n",
      "61\n",
      "61\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6091\n",
      "71\n",
      "1\n",
      "101\n",
      "101\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6092\n",
      "71\n",
      "9\n",
      "21\n",
      "21\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6093\n",
      "71\n",
      "1\n",
      "47\n",
      "47\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6094\n",
      "71\n",
      "1\n",
      "49\n",
      "49\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6095\n",
      "71\n",
      "1\n",
      "67\n",
      "67\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6096\n",
      "71\n",
      "1\n",
      "33\n",
      "33\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6097\n",
      "71\n",
      "1\n",
      "113\n",
      "113\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6098\n",
      "71\n",
      "1\n",
      "0\n",
      "0\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6099\n",
      "71\n",
      "1\n",
      "59\n",
      "59\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6100\n",
      "71\n",
      "1\n",
      "72\n",
      "72\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6101\n",
      "71\n",
      "9\n",
      "69\n",
      "69\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6102\n",
      "71\n",
      "1\n",
      "28\n",
      "28\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6103\n",
      "71\n",
      "9\n",
      "61\n",
      "61\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6104\n",
      "71\n",
      "1\n",
      "72\n",
      "72\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6105\n",
      "71\n",
      "1\n",
      "4\n",
      "4\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6106\n",
      "71\n",
      "1\n",
      "28\n",
      "28\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6107\n",
      "71\n",
      "1\n",
      "83\n",
      "83\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6108\n",
      "71\n",
      "1\n",
      "61\n",
      "61\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6109\n",
      "71\n",
      "1\n",
      "61\n",
      "61\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6110\n",
      "71\n",
      "1\n",
      "45\n",
      "45\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6111\n",
      "21\n",
      "1\n",
      "55\n",
      "55\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6112\n",
      "71\n",
      "1\n",
      "56\n",
      "56\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6113\n",
      "71\n",
      "1\n",
      "14\n",
      "14\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6114\n",
      "71\n",
      "1\n",
      "72\n",
      "72\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6115\n",
      "71\n",
      "1\n",
      "96\n",
      "96\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6116\n",
      "71\n",
      "1\n",
      "11\n",
      "11\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6117\n",
      "71\n",
      "1\n",
      "38\n",
      "38\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6118\n",
      "71\n",
      "1\n",
      "80\n",
      "80\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6119\n",
      "71\n",
      "1\n",
      "59\n",
      "59\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6120\n",
      "71\n",
      "1\n",
      "52\n",
      "52\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6121\n",
      "71\n",
      "1\n",
      "59\n",
      "59\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6122\n",
      "71\n",
      "1\n",
      "33\n",
      "33\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6123\n",
      "71\n",
      "9\n",
      "14\n",
      "14\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6124\n",
      "21\n",
      "1\n",
      "72\n",
      "72\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6125\n",
      "71\n",
      "1\n",
      "98\n",
      "98\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6126\n",
      "71\n",
      "1\n",
      "69\n",
      "69\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6127\n",
      "71\n",
      "1\n",
      "43\n",
      "43\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6128\n",
      "71\n",
      "1\n",
      "61\n",
      "61\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6129\n",
      "71\n",
      "1\n",
      "104\n",
      "104\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6130\n",
      "71\n",
      "71\n",
      "72\n",
      "72\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6131\n",
      "71\n",
      "1\n",
      "21\n",
      "21\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6132\n",
      "71\n",
      "1\n",
      "11\n",
      "11\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6133\n",
      "71\n",
      "1\n",
      "82\n",
      "83\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6134\n",
      "71\n",
      "1\n",
      "14\n",
      "14\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6135\n",
      "71\n",
      "1\n",
      "55\n",
      "55\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6136\n",
      "71\n",
      "1\n",
      "81\n",
      "81\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6137\n",
      "71\n",
      "1\n",
      "14\n",
      "14\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6138\n",
      "71\n",
      "1\n",
      "63\n",
      "63\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6139\n",
      "71\n",
      "9\n",
      "1\n",
      "1\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6140\n",
      "71\n",
      "4\n",
      "36\n",
      "36\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6141\n",
      "71\n",
      "1\n",
      "82\n",
      "82\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6142\n",
      "71\n",
      "1\n",
      "28\n",
      "28\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6143\n",
      "71\n",
      "1\n",
      "102\n",
      "102\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6144\n",
      "71\n",
      "1\n",
      "0\n",
      "0\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6145\n",
      "71\n",
      "1\n",
      "4\n",
      "4\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6146\n",
      "71\n",
      "1\n",
      "66\n",
      "66\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6147\n",
      "71\n",
      "1\n",
      "83\n",
      "83\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6148\n",
      "71\n",
      "1\n",
      "36\n",
      "36\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6149\n",
      "71\n",
      "1\n",
      "77\n",
      "77\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6150\n",
      "71\n",
      "1\n",
      "84\n",
      "84\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6151\n",
      "71\n",
      "1\n",
      "0\n",
      "0\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6152\n",
      "71\n",
      "1\n",
      "92\n",
      "92\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6153\n",
      "71\n",
      "38\n",
      "82\n",
      "82\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6154\n",
      "71\n",
      "1\n",
      "61\n",
      "61\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6155\n",
      "71\n",
      "1\n",
      "119\n",
      "119\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6156\n",
      "71\n",
      "1\n",
      "24\n",
      "24\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6157\n",
      "71\n",
      "1\n",
      "52\n",
      "52\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6158\n",
      "71\n",
      "1\n",
      "66\n",
      "66\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6159\n",
      "71\n",
      "1\n",
      "21\n",
      "21\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6160\n",
      "71\n",
      "1\n",
      "106\n",
      "106\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6161\n",
      "71\n",
      "1\n",
      "44\n",
      "44\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6162\n",
      "71\n",
      "1\n",
      "71\n",
      "71\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6163\n",
      "71\n",
      "1\n",
      "0\n",
      "0\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6164\n",
      "71\n",
      "1\n",
      "92\n",
      "92\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6165\n",
      "71\n",
      "1\n",
      "26\n",
      "26\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6166\n",
      "71\n",
      "1\n",
      "77\n",
      "77\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6167\n",
      "71\n",
      "1\n",
      "106\n",
      "106\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6168\n",
      "71\n",
      "1\n",
      "31\n",
      "31\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6169\n",
      "71\n",
      "1\n",
      "107\n",
      "107\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6170\n",
      "71\n",
      "1\n",
      "69\n",
      "69\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6171\n",
      "71\n",
      "1\n",
      "72\n",
      "72\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6172\n",
      "71\n",
      "1\n",
      "53\n",
      "53\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6173\n",
      "71\n",
      "1\n",
      "98\n",
      "98\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6174\n",
      "71\n",
      "1\n",
      "94\n",
      "94\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6175\n",
      "71\n",
      "1\n",
      "55\n",
      "55\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6176\n",
      "71\n",
      "1\n",
      "56\n",
      "56\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6177\n",
      "71\n",
      "1\n",
      "11\n",
      "11\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6178\n",
      "71\n",
      "1\n",
      "82\n",
      "82\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6179\n",
      "71\n",
      "1\n",
      "96\n",
      "96\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6180\n",
      "71\n",
      "1\n",
      "66\n",
      "66\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6181\n",
      "71\n",
      "1\n",
      "83\n",
      "83\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6182\n",
      "71\n",
      "1\n",
      "102\n",
      "102\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6183\n",
      "71\n",
      "1\n",
      "94\n",
      "94\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6184\n",
      "71\n",
      "1\n",
      "34\n",
      "34\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6185\n",
      "71\n",
      "1\n",
      "71\n",
      "71\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6186\n",
      "71\n",
      "1\n",
      "77\n",
      "77\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6187\n",
      "71\n",
      "1\n",
      "106\n",
      "106\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6188\n",
      "71\n",
      "1\n",
      "38\n",
      "38\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6189\n",
      "71\n",
      "1\n",
      "49\n",
      "49\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6190\n",
      "71\n",
      "1\n",
      "43\n",
      "43\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6191\n",
      "71\n",
      "1\n",
      "19\n",
      "18\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6192\n",
      "71\n",
      "1\n",
      "104\n",
      "104\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6193\n",
      "71\n",
      "4\n",
      "26\n",
      "26\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6194\n",
      "71\n",
      "1\n",
      "36\n",
      "36\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6195\n",
      "71\n",
      "1\n",
      "86\n",
      "86\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6196\n",
      "71\n",
      "1\n",
      "23\n",
      "23\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6197\n",
      "71\n",
      "1\n",
      "53\n",
      "53\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6198\n",
      "71\n",
      "1\n",
      "94\n",
      "94\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6199\n",
      "71\n",
      "1\n",
      "92\n",
      "92\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6200\n",
      "71\n",
      "38\n",
      "26\n",
      "26\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6201\n",
      "71\n",
      "1\n",
      "55\n",
      "55\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6202\n",
      "71\n",
      "1\n",
      "43\n",
      "43\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6203\n",
      "71\n",
      "1\n",
      "50\n",
      "50\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6204\n",
      "71\n",
      "9\n",
      "4\n",
      "4\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6205\n",
      "71\n",
      "1\n",
      "61\n",
      "61\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6206\n",
      "71\n",
      "1\n",
      "14\n",
      "14\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6207\n",
      "71\n",
      "1\n",
      "63\n",
      "63\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6208\n",
      "71\n",
      "1\n",
      "32\n",
      "32\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6209\n",
      "71\n",
      "1\n",
      "33\n",
      "33\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6210\n",
      "71\n",
      "1\n",
      "43\n",
      "43\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6211\n",
      "71\n",
      "1\n",
      "113\n",
      "113\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6212\n",
      "71\n",
      "1\n",
      "67\n",
      "67\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6213\n",
      "71\n",
      "1\n",
      "53\n",
      "53\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6214\n",
      "71\n",
      "1\n",
      "43\n",
      "43\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6215\n",
      "71\n",
      "9\n",
      "61\n",
      "61\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6216\n",
      "71\n",
      "1\n",
      "56\n",
      "56\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6217\n",
      "71\n",
      "1\n",
      "8\n",
      "8\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6218\n",
      "71\n",
      "1\n",
      "54\n",
      "54\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6219\n",
      "71\n",
      "1\n",
      "65\n",
      "65\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6220\n",
      "71\n",
      "4\n",
      "11\n",
      "11\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6221\n",
      "71\n",
      "1\n",
      "17\n",
      "17\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6222\n",
      "71\n",
      "1\n",
      "52\n",
      "52\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6223\n",
      "71\n",
      "1\n",
      "0\n",
      "0\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6224\n",
      "71\n",
      "1\n",
      "52\n",
      "52\n",
      "#########\n",
      "torch.float32\n",
      "torch.float32\n",
      "6225\n",
      "71\n",
      "1\n",
      "63\n",
      "63\n",
      "#########\n",
      "[71 71 71 ... 71 71 71]\n",
      "[1 1 1 ... 1 1 1]\n",
      "[64 72 52 ...  0 52 63]\n",
      "[64 72 52 ...  0 52 63]\n",
      "Positive Fidelity =  0.989718875502008\n",
      "Negative Fidelity =  0.9863453815261044\n",
      "0.02693759347347767\n",
      "[50]\n",
      "[0.989718875502008]\n",
      "[0.9863453815261044]\n",
      "[0.02693759347347767]\n",
      "  DummyExplainer\n",
      "/content/DummyExplainer_topk_results.csv\n",
      "   TopK  Fidelity+  Fidelity-  Characterization\n",
      "0    50   0.989719   0.986345          0.026938\n",
      "Run Time =  422.55626249313354\n",
      "<torch_geometric.loader.dataloader.DataLoader object at 0x7d605ff35f90>\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "#\n",
    "#!pip install torch_geometric\n",
    "#!pip install pdf2image\n",
    "#!apt-get install poppler-utils\n",
    "## !pip install captum\n",
    "#\n",
    "#from google.colab import files\n",
    "#files.upload()\n",
    "#\n",
    "#jupytext --to ipynb Comparative_Cheb_GCN.py\n",
    "# Don't forget to upload model.pth as well\n",
    "#!unzip numpy_data.zip\n",
    "\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.datasets import TUDataset, Planetoid\n",
    "from torch_geometric.nn import GCNConv, Set2Set\n",
    "from torch_geometric.explain import GNNExplainer\n",
    "import torch_geometric.transforms as T\n",
    "import torch\n",
    "#import torch.nn.functional as F\n",
    "import os\n",
    "from tqdm import tqdm, trange\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Loading saved model architecture\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import ChebConv\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.nn import TransformerConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.nn.pool import global_max_pool\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        # self.conv1 = GCNConv(6, 512, improved = True)\n",
    "        # self.conv2 = GCNConv(512, 256, improved = True)\n",
    "\n",
    "        # self.conv1 = ChebConv(6, 512, K = 2)\n",
    "        # self.conv2 = ChebConv(512,256, K = 2)\n",
    "\n",
    "        self.conv1 = ChebConv(6, 256, K = 3)\n",
    "        self.conv2 = ChebConv(256,256, K = 4)\n",
    "        self.conv3 = ChebConv(256, 256, K = 5)\n",
    "        # self.fc1 = Linear(256, 512)\n",
    "        # self.fc2 = Linear(512, 256)\n",
    "\n",
    "        # self.conv1 = GATConv(6, 256, heads = 4)\n",
    "        # self.conv2 = GATConv(256*4,64, heads = 1, concat=False)\n",
    "\n",
    "        # self.conv1 = TransformerConv(6, 200, heads = 3)\n",
    "        # self.conv2 = TransformerConv(200*3,256, heads = 1, concat=False)\n",
    "\n",
    "        self.lin = Linear(256, 120)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = x.relu()\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "        # = global_max_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # x = self.fc1(x)\n",
    "        # x = x.relu()\n",
    "        # x = self.fc2(x)\n",
    "        # x = x.relu()\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.2, training=self.training) #0.5\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=464)\n",
    "print(model)\n",
    "\n",
    "# print(os.getcwd()+ \"/model.pth\")\n",
    "# model_save_location = os.getcwd()+ \"/model.pth\"\n",
    "print(os.getcwd()+ \"/model_123.pt\")\n",
    "model_save_location = os.getcwd()+ \"/model_123.pt\"\n",
    "model.load_state_dict(torch.load(model_save_location, map_location=torch.device('cpu')))\n",
    "print(model.conv3)\n",
    "print(model.state_dict())\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import networkx as nx\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "print(os.getcwd())\n",
    "\n",
    "# +\n",
    "import time\n",
    "#Extract Training Data\n",
    "#Loads IEEE34 Bus Simulation Data\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "numpy_data = np.load(path+\"/new_data.npy\",allow_pickle = True)\n",
    "numpy_data = np.squeeze(numpy_data)\n",
    "print(numpy_data)\n",
    "print(numpy_data.shape)\n",
    "print(numpy_data.size)\n",
    "\n",
    "value_data = np.load(path+\"/new_labels.npy\",allow_pickle = True)\n",
    "print(value_data)\n",
    "print(value_data.shape)\n",
    "print(value_data.size)\n",
    "\n",
    "\n",
    "NodeIndex = np.load(path+\"/NodeIndex.npy\",allow_pickle = True)\n",
    "print(NodeIndex)\n",
    "print(NodeIndex.shape)\n",
    "print(NodeIndex.size)\n",
    "\n",
    "AdjacencyMatrix = np.load(path+\"/AdjacencyMatrix.npy\",allow_pickle = True)\n",
    "print(AdjacencyMatrix)\n",
    "print(AdjacencyMatrix.shape)\n",
    "print(AdjacencyMatrix.size)\n",
    "\n",
    "# +\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from torch.nn.functional import normalize\n",
    "\n",
    "\n",
    "encoder = ['150', '150R', '149', '1', '2', '3', '7', '4', '5', '6', '8', '12',\n",
    "'9', '13', '9R', '14', '34', '18', '11', '10', '15', '16', '17', '19',\n",
    "'21', '20', '22', '23', '24', '25', '25R', '26', '28', '27', '31',\n",
    "'33', '29', '30', '250', '32', '35', '36', '40', '37', '38', '39',\n",
    "'41', '42', '43', '44', '45', '47', '46', '48', '49', '50', '51',\n",
    "'151', '52', '53', '54', '55', '57', '56', '58', '60', '59', '61',\n",
    "'62', '63', '64', '65', '66', '67', '68', '72', '97', '69', '70',\n",
    "'71', '73', '76', '74', '75', '77', '86', '78', '79', '80', '81',\n",
    "'82', '84', '83', '85', '87', '88', '89', '90', '91', '92', '93',\n",
    "'94', '95', '96', '98', '99', '100', '450', '197', '101', '102',\n",
    "'105', '103', '104', '106', '108', '107', '109', '300', '110',\n",
    "'111', '112', '113', '114', '135', '152', '160R', '160', '61S', '610']\n",
    "#encoder = ['SourceBus', '800', '802', '806', '808', '810', '812', '814', '814r', '850',\n",
    "#'816', '818', '824', '820', '822', '826', '828', '830', '854', '832', '858',\n",
    "#'834', '860', '842', '836', '840', '862', '844', '846', '848', '852r', '888', '856', '852', '864', '838', '890']\n",
    "print(encoder)\n",
    "print(len(encoder))\n",
    "#research_paper_decoder = [0,0,1,2,3,4,5,6,6,6,6,7,8,9,10,11,8,12,12,13,14,15,21,15,16,16,16,17,18,18,13,13,19,13,20,22,23]\n",
    "research_paper_decoder = [0,0,0,1,2,3,4,5,6,7,8,9,10,11,10,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,72,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,14,11,61,61,63,119]\n",
    "print(research_paper_decoder)\n",
    "print(len(research_paper_decoder))\n",
    "FaultLocationLabels = value_data[:,3]\n",
    "\n",
    "for n in range(len(FaultLocationLabels)):\n",
    "    FaultLocationLabels[n]=research_paper_decoder[encoder.index(str(FaultLocationLabels[n]).upper())]\n",
    "\n",
    "\n",
    "\n",
    "y = FaultLocationLabels.astype(\"int64\")\n",
    "y = torch.from_numpy(y)\n",
    "x = numpy_data.astype(\"float32\")\n",
    "x = torch.from_numpy(x)\n",
    "\n",
    "NodeIndex = NodeIndex.astype(\"int64\")\n",
    "NodeIndex = NodeIndex.T\n",
    "NodeIndex = torch.from_numpy(NodeIndex)\n",
    "\n",
    "print(y)\n",
    "print(y.dtype)\n",
    "print(x)\n",
    "print(x.dtype)\n",
    "print(NodeIndex)\n",
    "print(NodeIndex.dtype)\n",
    "#\n",
    "print(x[0])\n",
    "print(normalize(x[0]))\n",
    "#\n",
    "result_translator = np.unique(FaultLocationLabels.astype(\"int64\")).tolist()\n",
    "print()\n",
    "total_data_list = []\n",
    "for n in range(len(x)):\n",
    "    #print(x[n])\n",
    "    #print(y[n])\n",
    "    DataObject = Data(x = x[n], edge_index = NodeIndex, y = y[n], is_undirected = True) #Testing with non-normalized data\n",
    "    #DataObject = Data(x = x[n], edge_index = NodeIndex, y = y[n], is_undirected = True)\n",
    "    DataObject.is_undirected = True\n",
    "    total_data_list.append(DataObject)\n",
    "#print('Y'*888)\n",
    "#print(total_data_list[0].x)\n",
    "\n",
    "print()\n",
    "#print(f'Dataset: {total_data_list}:')\n",
    "print('===================')\n",
    "print(f'Number of graphs: {len(total_data_list)}')\n",
    "print(f'Number of features: {total_data_list[0].num_features}')\n",
    "#print(f'Number of classes: {total_data_list[0].num_classes}')\n",
    "\n",
    "data = total_data_list[0]  # Get the first graph object.\n",
    "#print(data)\n",
    "#print(data.y)\n",
    "\n",
    "print()\n",
    "print(NormalizeFeatures(data.x))\n",
    "print(data.x)\n",
    "print('=============================================================')\n",
    "\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')\n",
    "\n",
    "from random import shuffle\n",
    "torch.manual_seed(12345)\n",
    "#total_data_list = total_data_list.shuffle()\n",
    "shuffle(total_data_list)\n",
    "\n",
    "train_dataset = total_data_list[:26000] #9150 is half\n",
    "test_dataset = total_data_list[26000:]\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')\n",
    "\n",
    "\n",
    "print(test_dataset[0].x)\n",
    "print(test_dataset[0])\n",
    "#print(train_dataset[0].x)\n",
    "\n",
    "for sample in range(len(test_dataset)):\n",
    "    # noise = np.random.normal(1,0.03, size = (37,6)) #0.09 #Uncomment for noise\n",
    "    # noise = noise.astype(\"float32\")\n",
    "    # noise = torch.from_numpy(noise)\n",
    "    # test_dataset[sample].x = noise*test_dataset[sample].x\n",
    "    test_dataset[sample].x = normalize(test_dataset[sample].x)\n",
    "    #print(sample)\n",
    "\n",
    "print('Y'*888)\n",
    "#print(train_dataset[0].x)\n",
    "print(test_dataset[0].x)\n",
    "print(test_dataset[0])\n",
    "##noise = np.random.normal(1,0.09, size = (16,6))\n",
    "##noise = noise.astype(\"float32\")\n",
    "##noise = torch.from_numpy(noise)\n",
    "print('=============================================================')\n",
    "##\n",
    "print(train_dataset[0].x)\n",
    "print(train_dataset[0])\n",
    "#print(train_dataset[0].x)\n",
    "\n",
    "for sample in range(len(train_dataset)):\n",
    "#    noise = np.random.normal(1,0.09, size = (16,6))\n",
    "#    #    noise = np.random.normal(1,0.09, size = (1,96))\n",
    "#    noise = noise.astype(\"float32\")\n",
    "#    noise = torch.from_numpy(noise)\n",
    "##    print(noise)\n",
    "##    X_test[sample] = X_test[sample]*noise[0]\n",
    "#    train_dataset[sample].x = noise*train_dataset[sample].x\n",
    "    train_dataset[sample].x = normalize(train_dataset[sample].x)\n",
    "    #print(sample)\n",
    "\n",
    "print('Y'*888)\n",
    "#print(train_dataset[0].x)\n",
    "print(train_dataset[0].x)\n",
    "print(train_dataset[0])\n",
    "##print(noise*test_dataset[0].x)\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "print(\"$\"*200)\n",
    "\n",
    "#################################################################################\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import ExplainerDataset\n",
    "from torch_geometric.datasets.graph_generator import BAGraph\n",
    "from torch_geometric.explain import Explainer, GNNExplainer, GraphMaskExplainer\n",
    "from torch_geometric.explain import DummyExplainer, PGExplainer\n",
    "from torch_geometric.nn import GCN\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "\n",
    "\n",
    "##dataset = ExplainerDataset(\n",
    "##    graph_generator=BAGraph(num_nodes=300, num_edges=5),\n",
    "##    motif_generator='house',\n",
    "##    num_motifs=80,\n",
    "##    transform=T.Constant(),\n",
    "##)\n",
    "#data = test_dataset[0]\n",
    "#print(data)\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from torch_geometric.explain import Explainer, Explanation\n",
    "from torch_geometric.explain.config import ExplanationType, ModelMode\n",
    "\n",
    "\n",
    "pos_fidelity_list = []\n",
    "neg_fidelity_list = []\n",
    "characterization_list = []\n",
    "#topk_list = [1,5,10,15]\n",
    "topk_list = [50]\n",
    "# topk_list = [1,5,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80]\n",
    "for topk in topk_list:\n",
    "    explainer = Explainer(\n",
    "        model=model,\n",
    "    #    algorithm=GNNExplainer(epochs=200),\n",
    "    #    algorithm=PGExplainer(epochs=2),\n",
    "        # algorithm=GraphMaskExplainer(num_layers = 3, epochs=200),\n",
    "       algorithm=DummyExplainer(),\n",
    "        explanation_type='model',\n",
    "        node_mask_type='attributes',\n",
    "        edge_mask_type='object',\n",
    "        model_config=dict(\n",
    "            mode='multiclass_classification',\n",
    "            task_level='graph',\n",
    "            return_type='log_probs',\n",
    "        ),\n",
    "        threshold_config=dict(\n",
    "#            threshold_type='topk',\n",
    "            threshold_type='topk_hard',\n",
    "            value =topk,\n",
    "        ),\n",
    "    )\n",
    "    count = 0\n",
    "    explain_y_hat_list = []\n",
    "    complement_y_hat_list = []\n",
    "    y_list = []\n",
    "    y_hat_list = []\n",
    "\n",
    "    for batch in test_loader:\n",
    "        count+=1\n",
    "        Edge_Index = batch.edge_index[:,:252]\n",
    "        Batch = batch.batch[:130]\n",
    "        label1 = batch.y[0].numpy().tolist()#\n",
    "        input = batch.x[0:130]#\n",
    "\n",
    "        #Uncomment lines below if running the PGExplainer (only supports phenomenon-based explanation)\n",
    "    #    for epoch in range(2):\n",
    "    #        loss = explainer.algorithm.train(epoch=epoch, model=model, x = input, edge_index=Edge_Index, batch = Batch)\n",
    "\n",
    "        y_hat = model(input, Edge_Index, Batch).argmax(dim=1).item()\n",
    "        explanation = explainer(x = input, edge_index = Edge_Index, batch = Batch)#, target = label1\n",
    "    #path = 'subgraph.pdf'\n",
    "    #explanation.visualize_graph(path)\n",
    "        node_mask = explanation.get('node_mask')\n",
    "        edge_mask = explanation.get('edge_mask')\n",
    "\n",
    "        #Two lines below focus on converting the soft masks to hard masks\n",
    "     #   node_mask = torch.tensor((node_mask-node_mask.mean())>0, dtype=torch.float32)\n",
    "    #    edge_mask = torch.tensor((edge_mask-edge_mask.mean())>0, dtype=torch.float32)\n",
    "\n",
    "#        print(node_mask)\n",
    "#        print(edge_mask)\n",
    "    #    print(\"7\"*88)\n",
    "        kwargs = {key: explanation[key] for key in explanation._model_args}\n",
    "        print(node_mask.dtype)\n",
    "        print(edge_mask.dtype)\n",
    "    #    y = explanation.target\n",
    "        y = label1\n",
    "        explain_y_hat = explainer.get_masked_prediction(\n",
    "                explanation.x,\n",
    "                explanation.edge_index,\n",
    "                node_mask,\n",
    "                edge_mask,\n",
    "                **kwargs,\n",
    "            )\n",
    "        explain_y_hat = explainer.get_target(explain_y_hat)\n",
    "        complement_y_hat = explainer.get_masked_prediction(\n",
    "            explanation.x,\n",
    "            explanation.edge_index,\n",
    "            1. - node_mask if node_mask is not None else None,\n",
    "            1. - edge_mask if edge_mask is not None else None,\n",
    "            **kwargs,\n",
    "        )\n",
    "        complement_y_hat = explainer.get_target(complement_y_hat)\n",
    "\n",
    "        explain_y_hat_list.append(explain_y_hat.numpy()[0])\n",
    "        complement_y_hat_list.append(complement_y_hat.numpy()[0])\n",
    "        y_list.append(y)\n",
    "        y_hat_list.append(y_hat)\n",
    "\n",
    "        print(count)\n",
    "        print(explain_y_hat.numpy()[0])\n",
    "        print(complement_y_hat.numpy()[0])\n",
    "        print(y)\n",
    "        print(y_hat)\n",
    "        print(\"#########\")\n",
    "\n",
    "#        if count > 1:\n",
    "#            break\n",
    "\n",
    "    explain_y_hat_list = np.array(explain_y_hat_list)\n",
    "    complement_y_hat_list = np.array(complement_y_hat_list)\n",
    "    y_list = np.array(y_list)\n",
    "    y_hat_list = np.array(y_hat_list)\n",
    "\n",
    "    print(explain_y_hat_list )\n",
    "    print(complement_y_hat_list )\n",
    "    print(y_list )\n",
    "    print(y_hat_list)\n",
    "    #.astype('float').mean()\n",
    "\n",
    "    pos_fidelity = 1. - (complement_y_hat_list == y_hat_list).astype('float').mean()\n",
    "    neg_fidelity = 1. - (explain_y_hat_list == y_hat_list).astype('float').mean()\n",
    "    print(\"Positive Fidelity = \", pos_fidelity) #positive fidelity reflects necessary explanation\n",
    "    # It's better for positive fidelity to be 1\n",
    "    print(\"Negative Fidelity = \", neg_fidelity) #negative fidelity reflects sufficient explanation\n",
    "    # It's better for negative fidelity to be 0\n",
    "    CharacterizationScore = 1./((0.5/pos_fidelity)+(0.5/(1-neg_fidelity)))\n",
    "    print(CharacterizationScore)\n",
    "\n",
    "    pos_fidelity_list.append(pos_fidelity)\n",
    "    neg_fidelity_list.append(neg_fidelity)\n",
    "    characterization_list.append(CharacterizationScore)\n",
    "\n",
    "print(topk_list)\n",
    "print(pos_fidelity_list)\n",
    "print(neg_fidelity_list)\n",
    "print(characterization_list)\n",
    "\n",
    "Topk_Results = pd.DataFrame(data = {'TopK' : topk_list,\n",
    "    'Fidelity+' : pos_fidelity_list,\n",
    "    'Fidelity-' : neg_fidelity_list,\n",
    "    'Characterization' : characterization_list})\n",
    "\n",
    "#Topk_Results.to_csv(path+'/'+str(explainer.algorithm)[:-2]+'_topk_results.csv', index = False)\n",
    "Topk_Results.to_csv(path+'/'+str(explainer.algorithm)[:-2]+'_topk_hard_results.csv', index = False)\n",
    "#.attribution_method_class.__name__\n",
    "print(\"  \"+str(explainer.algorithm)[:-2])\n",
    "#print(type(explainer.algorithm.attribution_method_class))\n",
    "print(path+'/'+str(explainer.algorithm)[:-2]+'_topk_results.csv')\n",
    "print(Topk_Results)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Run Time = \", end_time-start_time)\n",
    "\n",
    "print(test_loader)\n",
    "\n",
    "\n",
    "\n",
    "# from IPython.display import IFrame\n",
    "\n",
    "\n",
    "\n",
    "# # Specify the path to your PDF file\n",
    "# pdf_path = 'subgraph.pdf'\n",
    "\n",
    "# # Display the PDF inline\n",
    "# IFrame(pdf_path, width=600, height=300)\n",
    "\n",
    "# from pdf2image import convert_from_path\n",
    "\n",
    "# images = convert_from_path(\"subgraph.pdf\")\n",
    "# images[0]  # first page\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "#from pdf2image import convert_from_path\n",
    "#from IPython.display import display, Image\n",
    "#\n",
    "#images = convert_from_path(\"subgraph.pdf\")\n",
    "#for i, image in enumerate(images):\n",
    "#    fname = \"image\" + str(i) + \".png\"\n",
    "#    image.save(fname, \"PNG\")\n",
    "#Image(fname, width=800, height=1500)\n",
    "#\n",
    "#print(NodeIndex)\n",
    "#print(NodeIndex.shape)\n",
    "#print(NodeIndex.size)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
